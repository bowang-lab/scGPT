# test the model is order agnostic

# 1. test the pytorch transformer implementation
# 1.1. test same output for same input

# 1.2. test same output for different order of same input, padding appended to the end

# 1.3. test same output for different order of same input, padding at various positions

# 2. test the flash-attn implementation
# 2.1. test same output for same input

# 2.2. test same output for different order of same input, padding appended to the end

# 2.3. test different output for different order of same input, padding at various positions
