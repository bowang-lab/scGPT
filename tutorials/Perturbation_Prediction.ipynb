{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning Pre-trained Model for Perturbation Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bench-user/.apps/conda/envs/rtd/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "from pathlib import Path\n",
    "from typing import Iterable, List, Tuple, Dict, Union, Optional\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.io import mmread\n",
    "import scanpy as sc\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext._torchtext import (\n",
    "    Vocab as VocabPybind,\n",
    ")\n",
    "from torch_geometric.loader import DataLoader\n",
    "from gears import PertData, GEARS\n",
    "from gears.inference import compute_metrics, deeper_analysis, non_dropout_analysis\n",
    "from gears.utils import create_cell_graph_dataset_for_prediction\n",
    "\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "import scgpt as scg\n",
    "from scgpt.model import TransformerGenerator\n",
    "from scgpt.loss import (\n",
    "    masked_mse_loss,\n",
    "    criterion_neg_log_bernoulli,\n",
    "    masked_relative_error,\n",
    ")\n",
    "from scgpt.tokenizer import tokenize_batch, pad_batch, tokenize_and_pad_batch\n",
    "from scgpt.tokenizer.gene_tokenizer import GeneVocab\n",
    "from scgpt.utils import set_seed, map_raw_id_to_vocab_id\n",
    "\n",
    "\n",
    "\n",
    "matplotlib.rcParams[\"savefig.transparent\"] = False\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "set_seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Training Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding my own data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adata = sc.read_mtx(\"../dixit_dataset/K562_TF_d7.mtx.txt\")\n",
    "# transpose the data into cell x gene\n",
    "adata = adata.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add gene names to adata.var\n",
    "# convert the pandas df into a Series (you can turn df with\n",
    "# one row + mulitple columns or multiple rows + single column\n",
    "# into Series)\n",
    "# here 'use_col'=[1] extracts the needed column for labeling genes\n",
    "# squeeze() turns the df into a series that we can work with\n",
    "gene_names_series = pd.read_csv(\"../dixit_dataset/gene_names.csv\", usecols=[1]).squeeze()\n",
    "\n",
    "# add to the adata\n",
    "adata.var['gene_name'] = gene_names_series.values\n",
    "# adata.var_names_make_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add cell names onto adata.obs\n",
    "cell_names_series = pd.read_csv(\"../dixit_dataset/cell_name.csv\", usecols=[1]).squeeze()\n",
    "adata.obs['cell_names'] = cell_names_series.values\n",
    "\n",
    "# make sure the cell names are unique\n",
    "# adata.obs_names_make_unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  perturbation               cell_ids\n",
      "0   p_sgEGR1_2  AGGCTAACCCTCAC_p7d_B2\n",
      "0   p_sgEGR1_2  TATGAATGATGCCA_p7d_B2\n",
      "0   p_sgEGR1_2  AACCACGACATGCA_p7d_B2\n",
      "0   p_sgEGR1_2  GGGCCATGAAAAGC_p7d_B2\n",
      "0   p_sgEGR1_2  GCCACTACAGAGGC_p7d_B2\n"
     ]
    }
   ],
   "source": [
    "perturb = pd.read_csv(\"../dixit_dataset/cell_perturb_assignment.csv\")\n",
    "perturb.columns = ['perturbation','cell_ids']\n",
    "# Split the cell IDs into lists\n",
    "perturb['cell_ids'] = perturb['cell_ids'].str.split(', ')\n",
    "# Explode the DataFrame so each cell ID has its own row\n",
    "exploded_df = perturb.explode('cell_ids')\n",
    "print(exploded_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cell_ids\n",
       "AGGCTAACCCTCAC_p7d_B2    p_sgEGR1_2\n",
       "TATGAATGATGCCA_p7d_B2    p_sgEGR1_2\n",
       "AACCACGACATGCA_p7d_B2    p_sgEGR1_2\n",
       "GGGCCATGAAAAGC_p7d_B2    p_sgEGR1_2\n",
       "GCCACTACAGAGGC_p7d_B2    p_sgEGR1_2\n",
       "Name: perturbation, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn perturbation df (exploded_df) into series to map onto adata\n",
    "# cell_id as index and perturbation as value\n",
    "perturb_series = exploded_df.set_index('cell_ids')['perturbation']\n",
    "perturb_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using cell_names as index\n",
    "adata.obs.index = adata.obs['cell_names'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a mapping dictionary from cell_names to current index values\n",
    "mapping_dict = {cell_name: index for index, cell_name in enumerate(adata.obs['cell_names'])}\n",
    "\n",
    "# You can now use `mapping_dict` to find the index for a given cell_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AAACATACGCTACA_p7d_A1': 0,\n",
       " 'AAACATACTCCTGC_p7d_A1': 1,\n",
       " 'AAACATTGACGTTG_p7d_A1': 2,\n",
       " 'AAACATTGATTCGG_p7d_A1': 3,\n",
       " 'AAACATTGGAGCAG_p7d_A1': 4,\n",
       " 'AAACATTGTCCAGA_p7d_A1': 5,\n",
       " 'AAACATTGTCTCAT_p7d_A1': 6,\n",
       " 'AAACATTGTGAAGA_p7d_A1': 7,\n",
       " 'AAACCGTGAAGCAA_p7d_A1': 8,\n",
       " 'AAACCGTGATTGGC_p7d_A1': 9,\n",
       " 'AAACCGTGCTGAGT_p7d_A1': 10,\n",
       " 'AAACCGTGGAGGAC_p7d_A1': 11,\n",
       " 'AAACCGTGGCCCTT_p7d_A1': 12,\n",
       " 'AAACCGTGGCGATT_p7d_A1': 13,\n",
       " 'AAACCGTGTGGCAT_p7d_A1': 14,\n",
       " 'AAACGCACAAACAG_p7d_A1': 15,\n",
       " 'AAACGCACAAGGTA_p7d_A1': 16,\n",
       " 'AAACGCACGTTGGT_p7d_A1': 17,\n",
       " 'AAACGCTGACTAGC_p7d_A1': 18,\n",
       " 'AAACGCTGCGCAAT_p7d_A1': 19,\n",
       " 'AAACGCTGCGTTAG_p7d_A1': 20,\n",
       " 'AAACGCTGGACAGG_p7d_A1': 21,\n",
       " 'AAACGCTGTACAGC_p7d_A1': 22,\n",
       " 'AAACGCTGTGGTCA_p7d_A1': 23,\n",
       " 'AAACGCTGTTCACT_p7d_A1': 24,\n",
       " 'AAACGGCTAACGTC_p7d_A1': 25,\n",
       " 'AAACGGCTCTTTAC_p7d_A1': 26,\n",
       " 'AAACGGCTGCGGAA_p7d_A1': 27,\n",
       " 'AAACGGCTGGAGCA_p7d_A1': 28,\n",
       " 'AAACGGCTTTATCC_p7d_A1': 29,\n",
       " 'AAACGGCTTTCCGC_p7d_A1': 30,\n",
       " 'AAACTTGAAGCGGA_p7d_A1': 31,\n",
       " 'AAACTTGACCGCTT_p7d_A1': 32,\n",
       " 'AAACTTGAGTGAGG_p7d_A1': 33,\n",
       " 'AAACTTGATCTCGC_p7d_A1': 34,\n",
       " 'AAACTTGATGTGCA_p7d_A1': 35,\n",
       " 'AAAGACGAACCATG_p7d_A1': 36,\n",
       " 'AAAGACGAATGCCA_p7d_A1': 37,\n",
       " 'AAAGACGACATCAG_p7d_A1': 38,\n",
       " 'AAAGACGACCATAG_p7d_A1': 39,\n",
       " 'AAAGACGAGTGCTA_p7d_A1': 40,\n",
       " 'AAAGAGACCTGAGT_p7d_A1': 41,\n",
       " 'AAAGAGACTAGACC_p7d_A1': 42,\n",
       " 'AAAGATCTATCAGC_p7d_A1': 43,\n",
       " 'AAAGCAGAGAGAGC_p7d_A1': 44,\n",
       " 'AAAGCAGATCCGTC_p7d_A1': 45,\n",
       " 'AAAGCCTGACGTAC_p7d_A1': 46,\n",
       " 'AAAGCCTGCACTCC_p7d_A1': 47,\n",
       " 'AAAGCCTGGCTCCT_p7d_A1': 48,\n",
       " 'AAAGCCTGGGAGCA_p7d_A1': 49,\n",
       " 'AAAGCCTGGTGAGG_p7d_A1': 50,\n",
       " 'AAAGCCTGTTGTCT_p7d_A1': 51,\n",
       " 'AAAGGCCTACCAAC_p7d_A1': 52,\n",
       " 'AAAGGCCTCCGTAA_p7d_A1': 53,\n",
       " 'AAAGGCCTCTCCCA_p7d_A1': 54,\n",
       " 'AAAGGCCTCTCTCG_p7d_A1': 55,\n",
       " 'AAAGGCCTGTTCTT_p7d_A1': 56,\n",
       " 'AAAGGCCTTATCTC_p7d_A1': 57,\n",
       " 'AAAGGCCTTTGTGG_p7d_A1': 58,\n",
       " 'AAAGTTTGACAGCT_p7d_A1': 59,\n",
       " 'AAAGTTTGGGACTT_p7d_A1': 60,\n",
       " 'AAATACTGGCTGTA_p7d_A1': 61,\n",
       " 'AAATACTGGGTAGG_p7d_A1': 62,\n",
       " 'AAATACTGGGTCAT_p7d_A1': 63,\n",
       " 'AAATACTGTGAGGG_p7d_A1': 64,\n",
       " 'AAATCAACAAGTAG_p7d_A1': 65,\n",
       " 'AAATCAACATGGTC_p7d_A1': 66,\n",
       " 'AAATCAACGGAGGT_p7d_A1': 67,\n",
       " 'AAATCAACTCCGTC_p7d_A1': 68,\n",
       " 'AAATCAACTCTCCG_p7d_A1': 69,\n",
       " 'AAATCATGAAGAGT_p7d_A1': 70,\n",
       " 'AAATCATGAGCGGA_p7d_A1': 71,\n",
       " 'AAATCATGAGGGTG_p7d_A1': 72,\n",
       " 'AAATCATGCTACCC_p7d_A1': 73,\n",
       " 'AAATCATGCTACTT_p7d_A1': 74,\n",
       " 'AAATCATGTCTTTG_p7d_A1': 75,\n",
       " 'AAATCCCTCCATGA_p7d_A1': 76,\n",
       " 'AAATCCCTGTAAAG_p7d_A1': 77,\n",
       " 'AAATCCCTGTTGCA_p7d_A1': 78,\n",
       " 'AAATCTGAAACCAC_p7d_A1': 79,\n",
       " 'AAATCTGACTCTCG_p7d_A1': 80,\n",
       " 'AAATCTGAGACAAA_p7d_A1': 81,\n",
       " 'AAATCTGAGGTGGA_p7d_A1': 82,\n",
       " 'AAATCTGAGTTCTT_p7d_A1': 83,\n",
       " 'AAATCTGATCGTAG_p7d_A1': 84,\n",
       " 'AAATCTGATTGGTG_p7d_A1': 85,\n",
       " 'AAATGGGAACACTG_p7d_A1': 86,\n",
       " 'AAATGGGAATTTCC_p7d_A1': 87,\n",
       " 'AAATGGGACAATCG_p7d_A1': 88,\n",
       " 'AAATGGGACCTATT_p7d_A1': 89,\n",
       " 'AAATGTTGAGCCTA_p7d_A1': 90,\n",
       " 'AAATGTTGCTGCAA_p7d_A1': 91,\n",
       " 'AAATGTTGTCGCTC_p7d_A1': 92,\n",
       " 'AAATTCGACTGTGA_p7d_A1': 93,\n",
       " 'AAATTCGACTTCGC_p7d_A1': 94,\n",
       " 'AAATTCGATTACCT_p7d_A1': 95,\n",
       " 'AAATTGACAACCGT_p7d_A1': 96,\n",
       " 'AAATTGACCCTTCG_p7d_A1': 97,\n",
       " 'AAATTGACTTCACT_p7d_A1': 98,\n",
       " 'AACAAACTCGACTA_p7d_A1': 99,\n",
       " 'AACAAACTCTCTAT_p7d_A1': 100,\n",
       " 'AACAAACTGGACGA_p7d_A1': 101,\n",
       " 'AACAAACTTCATTC_p7d_A1': 102,\n",
       " 'AACAAACTTTTCAC_p7d_A1': 103,\n",
       " 'AACAATACCCTTGC_p7d_A1': 104,\n",
       " 'AACAATACCGATAC_p7d_A1': 105,\n",
       " 'AACAATACCGTGTA_p7d_A1': 106,\n",
       " 'AACAATACTATCTC_p7d_A1': 107,\n",
       " 'AACAATACTCTGGA_p7d_A1': 108,\n",
       " 'AACAATACTTTGCT_p7d_A1': 109,\n",
       " 'AACACGTGACACGT_p7d_A1': 110,\n",
       " 'AACACGTGACAGCT_p7d_A1': 111,\n",
       " 'AACACGTGATTCTC_p7d_A1': 112,\n",
       " 'AACACGTGCACACA_p7d_A1': 113,\n",
       " 'AACACGTGCCAGTA_p7d_A1': 114,\n",
       " 'AACACGTGCTCTTA_p7d_A1': 115,\n",
       " 'AACACGTGGCTATG_p7d_A1': 116,\n",
       " 'AACACGTGGGAGCA_p7d_A1': 117,\n",
       " 'AACACGTGGTGCTA_p7d_A1': 118,\n",
       " 'AACACGTGTGCTTT_p7d_A1': 119,\n",
       " 'AACACTCTAGCACT_p7d_A1': 120,\n",
       " 'AACACTCTGTTCTT_p7d_A1': 121,\n",
       " 'AACAGAGACGTGAT_p7d_A1': 122,\n",
       " 'AACAGAGAGAACCT_p7d_A1': 123,\n",
       " 'AACAGAGAGATGAA_p7d_A1': 124,\n",
       " 'AACAGAGATAGTCG_p7d_A1': 125,\n",
       " 'AACAGAGATCACGA_p7d_A1': 126,\n",
       " 'AACAGAGATTCCCG_p7d_A1': 127,\n",
       " 'AACAGCACACAGTC_p7d_A1': 128,\n",
       " 'AACAGCACAGTCTG_p7d_A1': 129,\n",
       " 'AACAGCACCCCTAC_p7d_A1': 130,\n",
       " 'AACAGCACCGTACA_p7d_A1': 131,\n",
       " 'AACAGCACGAAAGT_p7d_A1': 132,\n",
       " 'AACAGCACGAATGA_p7d_A1': 133,\n",
       " 'AACAGCACGGATCT_p7d_A1': 134,\n",
       " 'AACAGCACTTTGGG_p7d_A1': 135,\n",
       " 'AACATATGCCCTCA_p7d_A1': 136,\n",
       " 'AACATATGCCGTTC_p7d_A1': 137,\n",
       " 'AACATATGCCTACC_p7d_A1': 138,\n",
       " 'AACATATGCTACTT_p7d_A1': 139,\n",
       " 'AACATATGGGACAG_p7d_A1': 140,\n",
       " 'AACATATGGGTTCA_p7d_A1': 141,\n",
       " 'AACATTGAAGCTAC_p7d_A1': 142,\n",
       " 'AACATTGACGTGAT_p7d_A1': 143,\n",
       " 'AACATTGACTTTAC_p7d_A1': 144,\n",
       " 'AACATTGATTTCGT_p7d_A1': 145,\n",
       " 'AACCACGAACGGGA_p7d_A1': 146,\n",
       " 'AACCACGACATCAG_p7d_A1': 147,\n",
       " 'AACCACGAGTTCAG_p7d_A1': 148,\n",
       " 'AACCAGTGAAAGTG_p7d_A1': 149,\n",
       " 'AACCAGTGATTCTC_p7d_A1': 150,\n",
       " 'AACCAGTGCGCCTT_p7d_A1': 151,\n",
       " 'AACCAGTGTGTGCA_p7d_A1': 152,\n",
       " 'AACCCAGAACGCTA_p7d_A1': 153,\n",
       " 'AACCCAGAAGATGA_p7d_A1': 154,\n",
       " 'AACCCAGAATAAGG_p7d_A1': 155,\n",
       " 'AACCCAGACATTCT_p7d_A1': 156,\n",
       " 'AACCCAGACCACAA_p7d_A1': 157,\n",
       " 'AACCCAGACTCAGA_p7d_A1': 158,\n",
       " 'AACCCAGACTCCAC_p7d_A1': 159,\n",
       " 'AACCCAGATCGTAG_p7d_A1': 160,\n",
       " 'AACCCAGATGTCAG_p7d_A1': 161,\n",
       " 'AACCCAGATGTTTC_p7d_A1': 162,\n",
       " 'AACCCAGATTCGCC_p7d_A1': 163,\n",
       " 'AACCGATGCCTCCA_p7d_A1': 164,\n",
       " 'AACCGATGTTGACG_p7d_A1': 165,\n",
       " 'AACCGCCTGACACT_p7d_A1': 166,\n",
       " 'AACCGCCTGGGACA_p7d_A1': 167,\n",
       " 'AACCGCCTTACTCT_p7d_A1': 168,\n",
       " 'AACCTTACAAAGTG_p7d_A1': 169,\n",
       " 'AACCTTACAACGGG_p7d_A1': 170,\n",
       " 'AACCTTACAAGGGC_p7d_A1': 171,\n",
       " 'AACCTTACAGATCC_p7d_A1': 172,\n",
       " 'AACCTTACCCAGTA_p7d_A1': 173,\n",
       " 'AACCTTACCTACGA_p7d_A1': 174,\n",
       " 'AACCTTACCTAGCA_p7d_A1': 175,\n",
       " 'AACCTTACTCCAGA_p7d_A1': 176,\n",
       " 'AACCTTTGACGCTA_p7d_A1': 177,\n",
       " 'AACCTTTGCTTCGC_p7d_A1': 178,\n",
       " 'AACCTTTGGGAAAT_p7d_A1': 179,\n",
       " 'AACCTTTGTATCGG_p7d_A1': 180,\n",
       " 'AACCTTTGTGTCCC_p7d_A1': 181,\n",
       " 'AACCTTTGTTCTGT_p7d_A1': 182,\n",
       " 'AACGCAACCAAAGA_p7d_A1': 183,\n",
       " 'AACGCAACCATTGG_p7d_A1': 184,\n",
       " 'AACGCAACGAACTC_p7d_A1': 185,\n",
       " 'AACGCATGCCTCGT_p7d_A1': 186,\n",
       " 'AACGCATGCGGGAA_p7d_A1': 187,\n",
       " 'AACGCATGGACACT_p7d_A1': 188,\n",
       " 'AACGCATGGTAGGG_p7d_A1': 189,\n",
       " 'AACGCCCTACACAC_p7d_A1': 190,\n",
       " 'AACGCCCTATCTCT_p7d_A1': 191,\n",
       " 'AACGCCCTGCTGAT_p7d_A1': 192,\n",
       " 'AACGCCCTGGCGAA_p7d_A1': 193,\n",
       " 'AACGCCCTTAGCCA_p7d_A1': 194,\n",
       " 'AACGCCCTTGCTTT_p7d_A1': 195,\n",
       " 'AACGGTACAAGGGC_p7d_A1': 196,\n",
       " 'AACGGTACATGACC_p7d_A1': 197,\n",
       " 'AACGGTACCAAGCT_p7d_A1': 198,\n",
       " 'AACGGTACGCAGTT_p7d_A1': 199,\n",
       " 'AACGGTACTCATTC_p7d_A1': 200,\n",
       " 'AACGGTACTGAGGG_p7d_A1': 201,\n",
       " 'AACGGTACTTCACT_p7d_A1': 202,\n",
       " 'AACGGTTGAGTCGT_p7d_A1': 203,\n",
       " 'AACGGTTGGCAGTT_p7d_A1': 204,\n",
       " 'AACGTCGAAAGCAA_p7d_A1': 205,\n",
       " 'AACGTCGAGAGGTG_p7d_A1': 206,\n",
       " 'AACGTCGAGGCGAA_p7d_A1': 207,\n",
       " 'AACGTCGATTCAGG_p7d_A1': 208,\n",
       " 'AACGTGTGAAGGTA_p7d_A1': 209,\n",
       " 'AACGTGTGATGCTG_p7d_A1': 210,\n",
       " 'AACGTGTGTGCGTA_p7d_A1': 211,\n",
       " 'AACGTTCTCGTGTA_p7d_A1': 212,\n",
       " 'AACGTTCTCTCTCG_p7d_A1': 213,\n",
       " 'AACGTTCTGCCAAT_p7d_A1': 214,\n",
       " 'AACGTTCTGCGGAA_p7d_A1': 215,\n",
       " 'AACGTTCTGGACAG_p7d_A1': 216,\n",
       " 'AACGTTCTGTTACG_p7d_A1': 217,\n",
       " 'AACGTTCTGTTCAG_p7d_A1': 218,\n",
       " 'AACGTTCTTGGTAC_p7d_A1': 219,\n",
       " 'AACGTTCTTTCAGG_p7d_A1': 220,\n",
       " 'AACTACCTCCGCTT_p7d_A1': 221,\n",
       " 'AACTACCTCGACAT_p7d_A1': 222,\n",
       " 'AACTACCTGAATCC_p7d_A1': 223,\n",
       " 'AACTACCTGCTGTA_p7d_A1': 224,\n",
       " 'AACTACCTGGAAAT_p7d_A1': 225,\n",
       " 'AACTACCTTCGACA_p7d_A1': 226,\n",
       " 'AACTACCTTCGCAA_p7d_A1': 227,\n",
       " 'AACTACCTTCGTTT_p7d_A1': 228,\n",
       " 'AACTACCTTTATCC_p7d_A1': 229,\n",
       " 'AACTCACTACTCTT_p7d_A1': 230,\n",
       " 'AACTCACTCCTACC_p7d_A1': 231,\n",
       " 'AACTCACTCGCTAA_p7d_A1': 232,\n",
       " 'AACTCACTCTTTAC_p7d_A1': 233,\n",
       " 'AACTCACTGCCATA_p7d_A1': 234,\n",
       " 'AACTCACTTGGTGT_p7d_A1': 235,\n",
       " 'AACTCACTTGGTTG_p7d_A1': 236,\n",
       " 'AACTCGGAACCTCC_p7d_A1': 237,\n",
       " 'AACTCGGACGCATA_p7d_A1': 238,\n",
       " 'AACTCGGAGCATCA_p7d_A1': 239,\n",
       " 'AACTCGGATTCGTT_p7d_A1': 240,\n",
       " 'AACTCTTGAAGGTA_p7d_A1': 241,\n",
       " 'AACTCTTGGGACGA_p7d_A1': 242,\n",
       " 'AACTCTTGTCGCCT_p7d_A1': 243,\n",
       " 'AACTGTCTCCTAAG_p7d_A1': 244,\n",
       " 'AACTGTCTGACACT_p7d_A1': 245,\n",
       " 'AACTGTCTGCAGTT_p7d_A1': 246,\n",
       " 'AACTGTCTGGTGAG_p7d_A1': 247,\n",
       " 'AACTGTCTTAAGCC_p7d_A1': 248,\n",
       " 'AACTTGCTCCTTTA_p7d_A1': 249,\n",
       " 'AACTTGCTCTAGCA_p7d_A1': 250,\n",
       " 'AACTTGCTGCGATT_p7d_A1': 251,\n",
       " 'AACTTGCTTAAGCC_p7d_A1': 252,\n",
       " 'AAGAACGAAGAACA_p7d_A1': 253,\n",
       " 'AAGAACGACTACTT_p7d_A1': 254,\n",
       " 'AAGAACGACTTGGA_p7d_A1': 255,\n",
       " 'AAGAACGAGCGAGA_p7d_A1': 256,\n",
       " 'AAGAACGATAACGC_p7d_A1': 257,\n",
       " 'AAGAACGATAGCGT_p7d_A1': 258,\n",
       " 'AAGAAGACACGGAG_p7d_A1': 259,\n",
       " 'AAGAAGACATGCTG_p7d_A1': 260,\n",
       " 'AAGAAGACCTGATG_p7d_A1': 261,\n",
       " 'AAGAAGACGAATGA_p7d_A1': 262,\n",
       " 'AAGAAGACTATCGG_p7d_A1': 263,\n",
       " 'AAGAAGACTGGTCA_p7d_A1': 264,\n",
       " 'AAGAATCTCGTTAG_p7d_A1': 265,\n",
       " 'AAGAATCTTGAGAA_p7d_A1': 266,\n",
       " 'AAGAATCTTTCAGG_p7d_A1': 267,\n",
       " 'AAGACAGAATGGTC_p7d_A1': 268,\n",
       " 'AAGACAGACGTACA_p7d_A1': 269,\n",
       " 'AAGACAGAGTATGC_p7d_A1': 270,\n",
       " 'AAGACAGAGTCATG_p7d_A1': 271,\n",
       " 'AAGACAGATAAAGG_p7d_A1': 272,\n",
       " 'AAGACAGATCGTTT_p7d_A1': 273,\n",
       " 'AAGAGATGACTTTC_p7d_A1': 274,\n",
       " 'AAGAGATGAGATCC_p7d_A1': 275,\n",
       " 'AAGAGATGCATCAG_p7d_A1': 276,\n",
       " 'AAGAGATGCGAGAG_p7d_A1': 277,\n",
       " 'AAGAGATGTAAAGG_p7d_A1': 278,\n",
       " 'AAGATGGACAGTTG_p7d_A1': 279,\n",
       " 'AAGATGGAGTACCA_p7d_A1': 280,\n",
       " 'AAGATGGAGTAGCT_p7d_A1': 281,\n",
       " 'AAGATGGAGTATGC_p7d_A1': 282,\n",
       " 'AAGATGGATCGATG_p7d_A1': 283,\n",
       " 'AAGATGGATTATCC_p7d_A1': 284,\n",
       " 'AAGATTACATTGGC_p7d_A1': 285,\n",
       " 'AAGATTACGTCCTC_p7d_A1': 286,\n",
       " 'AAGATTACTGTAGC_p7d_A1': 287,\n",
       " 'AAGCAAGAGCCATA_p7d_A1': 288,\n",
       " 'AAGCAAGAGGTGTT_p7d_A1': 289,\n",
       " 'AAGCACTGTTTACC_p7d_A1': 290,\n",
       " 'AAGCCAACCTACTT_p7d_A1': 291,\n",
       " 'AAGCCAACGATAGA_p7d_A1': 292,\n",
       " 'AAGCCAACTGTCCC_p7d_A1': 293,\n",
       " 'AAGCCAACTTACTC_p7d_A1': 294,\n",
       " 'AAGCCATGAGCCTA_p7d_A1': 295,\n",
       " 'AAGCCATGAGTCTG_p7d_A1': 296,\n",
       " 'AAGCCATGCCTCAC_p7d_A1': 297,\n",
       " 'AAGCCATGGGCATT_p7d_A1': 298,\n",
       " 'AAGCCATGGTATGC_p7d_A1': 299,\n",
       " 'AAGCCATGGTGTTG_p7d_A1': 300,\n",
       " 'AAGCCTGAAAGGGC_p7d_A1': 301,\n",
       " 'AAGCCTGACAGAAA_p7d_A1': 302,\n",
       " 'AAGCCTGAGAACCT_p7d_A1': 303,\n",
       " 'AAGCCTGATCCTTA_p7d_A1': 304,\n",
       " 'AAGCCTGATTCTTG_p7d_A1': 305,\n",
       " 'AAGCGACTTTCCAT_p7d_A1': 306,\n",
       " 'AAGCGACTTTTCGT_p7d_A1': 307,\n",
       " 'AAGCGTACAATGCC_p7d_A1': 308,\n",
       " 'AAGCGTACCTTCTA_p7d_A1': 309,\n",
       " 'AAGCGTACGGAAAT_p7d_A1': 310,\n",
       " 'AAGCGTACGGAGCA_p7d_A1': 311,\n",
       " 'AAGCGTACTGAGGG_p7d_A1': 312,\n",
       " 'AAGCGTACTGCTTT_p7d_A1': 313,\n",
       " 'AAGGCTACTGAGGG_p7d_A1': 314,\n",
       " 'AAGGCTTGATGTCG_p7d_A1': 315,\n",
       " 'AAGGCTTGCTGTCC_p7d_A1': 316,\n",
       " 'AAGGCTTGTTGAGC_p7d_A1': 317,\n",
       " 'AAGGCTTGTTGTCT_p7d_A1': 318,\n",
       " 'AAGGCTTGTTTCGT_p7d_A1': 319,\n",
       " 'AAGGCTTGTTTGTC_p7d_A1': 320,\n",
       " 'AAGGTCACACCTAG_p7d_A1': 321,\n",
       " 'AAGGTCTGCATGCA_p7d_A1': 322,\n",
       " 'AAGGTCTGCCCAAA_p7d_A1': 323,\n",
       " 'AAGGTCTGTATCTC_p7d_A1': 324,\n",
       " 'AAGGTCTGTGAGCT_p7d_A1': 325,\n",
       " 'AAGGTCTGTGTGCA_p7d_A1': 326,\n",
       " 'AAGGTGCTCAGTCA_p7d_A1': 327,\n",
       " 'AAGGTGCTGTCGTA_p7d_A1': 328,\n",
       " 'AAGGTGCTTCCTCG_p7d_A1': 329,\n",
       " 'AAGGTGCTTTCTTG_p7d_A1': 330,\n",
       " 'AAGTAACTCCAGTA_p7d_A1': 331,\n",
       " 'AAGTAACTCTACCC_p7d_A1': 332,\n",
       " 'AAGTAACTGTTGCA_p7d_A1': 333,\n",
       " 'AAGTAGGAAGCTAC_p7d_A1': 334,\n",
       " 'AAGTAGGACGAGTT_p7d_A1': 335,\n",
       " 'AAGTAGGAGGATCT_p7d_A1': 336,\n",
       " 'AAGTAGGATGTTTC_p7d_A1': 337,\n",
       " 'AAGTATACCTTGGA_p7d_A1': 338,\n",
       " 'AAGTATACGAAAGT_p7d_A1': 339,\n",
       " 'AAGTATACGGTCTA_p7d_A1': 340,\n",
       " 'AAGTCCGAACCATG_p7d_A1': 341,\n",
       " 'AAGTCCGAGGTAAA_p7d_A1': 342,\n",
       " 'AAGTCCGATTCGTT_p7d_A1': 343,\n",
       " 'AAGTCTCTATACCG_p7d_A1': 344,\n",
       " 'AAGTCTCTGAGGAC_p7d_A1': 345,\n",
       " 'AAGTCTCTGTCTGA_p7d_A1': 346,\n",
       " 'AAGTCTCTTTCGGA_p7d_A1': 347,\n",
       " 'AAGTGCACAACAGA_p7d_A1': 348,\n",
       " 'AAGTGCACCTCAGA_p7d_A1': 349,\n",
       " 'AAGTGCACTAGCGT_p7d_A1': 350,\n",
       " 'AAGTGCACTCAGAC_p7d_A1': 351,\n",
       " 'AAGTGCACTTCATC_p7d_A1': 352,\n",
       " 'AAGTGGCTACCTGA_p7d_A1': 353,\n",
       " 'AAGTGGCTGCGAGA_p7d_A1': 354,\n",
       " 'AAGTGGCTGCGTAT_p7d_A1': 355,\n",
       " 'AAGTGGCTTGGTCA_p7d_A1': 356,\n",
       " 'AAGTGGCTTTCCAT_p7d_A1': 357,\n",
       " 'AAGTTATGGGGTGA_p7d_A1': 358,\n",
       " 'AAGTTATGTTACTC_p7d_A1': 359,\n",
       " 'AAGTTCCTAACCAC_p7d_A1': 360,\n",
       " 'AAGTTCCTAGCGGA_p7d_A1': 361,\n",
       " 'AAGTTCCTCAACTG_p7d_A1': 362,\n",
       " 'AAGTTCCTGAGAGC_p7d_A1': 363,\n",
       " 'AAGTTCCTGGTATC_p7d_A1': 364,\n",
       " 'AAGTTCCTTCTTAC_p7d_A1': 365,\n",
       " 'AAGTTCCTTGGTCA_p7d_A1': 366,\n",
       " 'AATAACACAAAAGC_p7d_A1': 367,\n",
       " 'AATAACACACTACG_p7d_A1': 368,\n",
       " 'AATAACACAGCATC_p7d_A1': 369,\n",
       " 'AATAACACCCAGTA_p7d_A1': 370,\n",
       " 'AATAACACTCTTCA_p7d_A1': 371,\n",
       " 'AATAACACTGCCAA_p7d_A1': 372,\n",
       " 'AATAACACTGTTCT_p7d_A1': 373,\n",
       " 'AATAAGCTATAAGG_p7d_A1': 374,\n",
       " 'AATAAGCTATCTCT_p7d_A1': 375,\n",
       " 'AATAAGCTCCAACA_p7d_A1': 376,\n",
       " 'AATAAGCTCCCTAC_p7d_A1': 377,\n",
       " 'AATAAGCTCGACAT_p7d_A1': 378,\n",
       " 'AATAAGCTCGGGAA_p7d_A1': 379,\n",
       " 'AATAAGCTGGTCAT_p7d_A1': 380,\n",
       " 'AATAAGCTGTCAAC_p7d_A1': 381,\n",
       " 'AATAAGCTTTGCTT_p7d_A1': 382,\n",
       " 'AATACCCTCGTCTC_p7d_A1': 383,\n",
       " 'AATACCCTTATTCC_p7d_A1': 384,\n",
       " 'AATACCCTTCGCCT_p7d_A1': 385,\n",
       " 'AATACCCTTGTCTT_p7d_A1': 386,\n",
       " 'AATACCCTTTCTCA_p7d_A1': 387,\n",
       " 'AATACTGAGGTACT_p7d_A1': 388,\n",
       " 'AATAGGGAACGGAG_p7d_A1': 389,\n",
       " 'AATAGGGAGACGAG_p7d_A1': 390,\n",
       " 'AATAGGGAGCATCA_p7d_A1': 391,\n",
       " 'AATAGGGATTGCGA_p7d_A1': 392,\n",
       " 'AATAGGGATTTGGG_p7d_A1': 393,\n",
       " 'AATATCGACACTGA_p7d_A1': 394,\n",
       " 'AATCAAACGGAAGC_p7d_A1': 395,\n",
       " 'AATCAAACTACAGC_p7d_A1': 396,\n",
       " 'AATCAAACTAGCGT_p7d_A1': 397,\n",
       " 'AATCAAACTCGTGA_p7d_A1': 398,\n",
       " 'AATCCGGAATTCTC_p7d_A1': 399,\n",
       " 'AATCCGGACAGTCA_p7d_A1': 400,\n",
       " 'AATCCGGAGAGCAG_p7d_A1': 401,\n",
       " 'AATCCGGATAAAGG_p7d_A1': 402,\n",
       " 'AATCCGGATATCTC_p7d_A1': 403,\n",
       " 'AATCCGGATTGTCT_p7d_A1': 404,\n",
       " 'AATCCTACAGCCTA_p7d_A1': 405,\n",
       " 'AATCCTACGAGGCA_p7d_A1': 406,\n",
       " 'AATCCTACGTTGTG_p7d_A1': 407,\n",
       " 'AATCCTACTCTCCG_p7d_A1': 408,\n",
       " 'AATCCTTGGACGAG_p7d_A1': 409,\n",
       " 'AATCCTTGTCTTAC_p7d_A1': 410,\n",
       " 'AATCCTTGTTACTC_p7d_A1': 411,\n",
       " 'AATCGGTGCTGAGT_p7d_A1': 412,\n",
       " 'AATCGGTGGACAGG_p7d_A1': 413,\n",
       " 'AATCGGTGGGAAAT_p7d_A1': 414,\n",
       " 'AATCGGTGGTTTCT_p7d_A1': 415,\n",
       " 'AATCGGTGTAAAGG_p7d_A1': 416,\n",
       " 'AATCGGTGTCCTTA_p7d_A1': 417,\n",
       " 'AATCTAGAGTAGCT_p7d_A1': 418,\n",
       " 'AATCTAGAGTCCTC_p7d_A1': 419,\n",
       " 'AATCTCACGTTCGA_p7d_A1': 420,\n",
       " 'AATCTCACTCCGAA_p7d_A1': 421,\n",
       " 'AATCTCTGAGTGTC_p7d_A1': 422,\n",
       " 'AATCTCTGGCCAAT_p7d_A1': 423,\n",
       " 'AATCTCTGTACAGC_p7d_A1': 424,\n",
       " 'AATGAGGACCTCGT_p7d_A1': 425,\n",
       " 'AATGAGGACGCTAA_p7d_A1': 426,\n",
       " 'AATGAGGATTTCAC_p7d_A1': 427,\n",
       " 'AATGATACCCTCCA_p7d_A1': 428,\n",
       " 'AATGCGTGCTTATC_p7d_A1': 429,\n",
       " 'AATGCGTGGCCATA_p7d_A1': 430,\n",
       " 'AATGCGTGGGATCT_p7d_A1': 431,\n",
       " 'AATGCGTGTCTGGA_p7d_A1': 432,\n",
       " 'AATGGAGAACACGT_p7d_A1': 433,\n",
       " 'AATGGAGAGAAGGC_p7d_A1': 434,\n",
       " 'AATGGAGAGCGATT_p7d_A1': 435,\n",
       " 'AATGGAGAGGTGAG_p7d_A1': 436,\n",
       " 'AATGGAGATAGAAG_p7d_A1': 437,\n",
       " 'AATGGAGATCTTCA_p7d_A1': 438,\n",
       " 'AATGGCTGACGTAC_p7d_A1': 439,\n",
       " 'AATGGCTGAGGCGA_p7d_A1': 440,\n",
       " 'AATGGCTGCACTGA_p7d_A1': 441,\n",
       " 'AATGGCTGCCTTTA_p7d_A1': 442,\n",
       " 'AATGGCTGCGTAAC_p7d_A1': 443,\n",
       " 'AATGGCTGCTCTAT_p7d_A1': 444,\n",
       " 'AATGGCTGGAGGCA_p7d_A1': 445,\n",
       " 'AATGGCTGGGGATG_p7d_A1': 446,\n",
       " 'AATGTAACACGGGA_p7d_A1': 447,\n",
       " 'AATGTAACGTATCG_p7d_A1': 448,\n",
       " 'AATGTAACTTGGTG_p7d_A1': 449,\n",
       " 'AATGTCCTACTAGC_p7d_A1': 450,\n",
       " 'AATGTCCTATAAGG_p7d_A1': 451,\n",
       " 'AATGTCCTCATGAC_p7d_A1': 452,\n",
       " 'AATGTCCTCCGCTT_p7d_A1': 453,\n",
       " 'AATGTCCTCGCTAA_p7d_A1': 454,\n",
       " 'AATGTCCTCGTACA_p7d_A1': 455,\n",
       " 'AATGTCCTCGTAGT_p7d_A1': 456,\n",
       " 'AATGTCCTCTACCC_p7d_A1': 457,\n",
       " 'AATGTCCTGCCATA_p7d_A1': 458,\n",
       " 'AATGTCCTGGAAGC_p7d_A1': 459,\n",
       " 'AATGTTGAAAAGCA_p7d_A1': 460,\n",
       " 'AATGTTGAAAAGTG_p7d_A1': 461,\n",
       " 'AATGTTGAAGAATG_p7d_A1': 462,\n",
       " 'AATGTTGAAGCGTT_p7d_A1': 463,\n",
       " 'AATGTTGACTTTAC_p7d_A1': 464,\n",
       " 'AATGTTGAGATAAG_p7d_A1': 465,\n",
       " 'AATGTTGAGCGTAT_p7d_A1': 466,\n",
       " 'AATGTTGAGCTTCC_p7d_A1': 467,\n",
       " 'AATGTTGAGGGTGA_p7d_A1': 468,\n",
       " 'AATGTTGAGGTATC_p7d_A1': 469,\n",
       " 'AATGTTGAGGTTAC_p7d_A1': 470,\n",
       " 'AATGTTGATCGTGA_p7d_A1': 471,\n",
       " 'AATTACGAAAAAGC_p7d_A1': 472,\n",
       " 'AATTACGACAGTCA_p7d_A1': 473,\n",
       " 'AATTACGATGCCTC_p7d_A1': 474,\n",
       " 'AATTCCTGAGTCGT_p7d_A1': 475,\n",
       " 'AATTCCTGCAAGCT_p7d_A1': 476,\n",
       " 'AATTCCTGCTGGTA_p7d_A1': 477,\n",
       " 'AATTCCTGGTCACA_p7d_A1': 478,\n",
       " 'AATTCCTGGTTCAG_p7d_A1': 479,\n",
       " 'AATTCCTGTGTGGT_p7d_A1': 480,\n",
       " 'AATTGATGCATGGT_p7d_A1': 481,\n",
       " 'AATTGATGCCGTAA_p7d_A1': 482,\n",
       " 'AATTGATGCCTAAG_p7d_A1': 483,\n",
       " 'AATTGTGAACTGTG_p7d_A1': 484,\n",
       " 'AATTGTGAAGTCAC_p7d_A1': 485,\n",
       " 'AATTGTGAATTCGG_p7d_A1': 486,\n",
       " 'AATTGTGATCTATC_p7d_A1': 487,\n",
       " 'AATTGTGATCTCTA_p7d_A1': 488,\n",
       " 'AATTGTGATTCTTG_p7d_A1': 489,\n",
       " 'ACAAAGGACCGCTT_p7d_A1': 490,\n",
       " 'ACAAAGGACGAGTT_p7d_A1': 491,\n",
       " 'ACAAATTGACGGGA_p7d_A1': 492,\n",
       " 'ACAAATTGATCTTC_p7d_A1': 493,\n",
       " 'ACAAATTGCGCAAT_p7d_A1': 494,\n",
       " 'ACAAATTGCGTACA_p7d_A1': 495,\n",
       " 'ACAAATTGGGCGAA_p7d_A1': 496,\n",
       " 'ACAAATTGTGTTCT_p7d_A1': 497,\n",
       " 'ACAACCGACATCAG_p7d_A1': 498,\n",
       " 'ACAACCGACCTCGT_p7d_A1': 499,\n",
       " 'ACAACCGAGACGAG_p7d_A1': 500,\n",
       " 'ACAACCGATCAAGC_p7d_A1': 501,\n",
       " 'ACAACCGATCTACT_p7d_A1': 502,\n",
       " 'ACAAGAGAAGGTTC_p7d_A1': 503,\n",
       " 'ACAAGAGAGTATGC_p7d_A1': 504,\n",
       " 'ACAAGAGATGGTTG_p7d_A1': 505,\n",
       " 'ACAAGAGATTCGGA_p7d_A1': 506,\n",
       " 'ACAAGAGATTGGTG_p7d_A1': 507,\n",
       " 'ACAAGCACCCTACC_p7d_A1': 508,\n",
       " 'ACAAGCACCTCATT_p7d_A1': 509,\n",
       " 'ACAAGCACGTCCTC_p7d_A1': 510,\n",
       " 'ACAAGCACTCGATG_p7d_A1': 511,\n",
       " 'ACAATAACAAACAG_p7d_A1': 512,\n",
       " 'ACAATAACACTGTG_p7d_A1': 513,\n",
       " 'ACAATAACCCTTAT_p7d_A1': 514,\n",
       " 'ACAATAACGCTACA_p7d_A1': 515,\n",
       " 'ACAATAACTCCTTA_p7d_A1': 516,\n",
       " 'ACAATAACTCGTTT_p7d_A1': 517,\n",
       " 'ACAATAACTGAGGG_p7d_A1': 518,\n",
       " 'ACAATAACTGTGGT_p7d_A1': 519,\n",
       " 'ACAATCCTACTAGC_p7d_A1': 520,\n",
       " 'ACAATTGAAAACAG_p7d_A1': 521,\n",
       " 'ACAATTGAAGCTAC_p7d_A1': 522,\n",
       " 'ACAATTGACACTTT_p7d_A1': 523,\n",
       " 'ACAATTGACGCAAT_p7d_A1': 524,\n",
       " 'ACAATTGAGGACAG_p7d_A1': 525,\n",
       " 'ACACAGACAACTGC_p7d_A1': 526,\n",
       " 'ACACAGACGCTAAC_p7d_A1': 527,\n",
       " 'ACACAGACGTAGGG_p7d_A1': 528,\n",
       " 'ACACATCTGTTCGA_p7d_A1': 529,\n",
       " 'ACACATCTTGCAGT_p7d_A1': 530,\n",
       " 'ACACATCTTTCGCC_p7d_A1': 531,\n",
       " 'ACACCAGAACCTTT_p7d_A1': 532,\n",
       " 'ACACCAGAAGAACA_p7d_A1': 533,\n",
       " 'ACACCAGAAGGAGC_p7d_A1': 534,\n",
       " 'ACACCAGACGTGTA_p7d_A1': 535,\n",
       " 'ACACCAGAGTATGC_p7d_A1': 536,\n",
       " 'ACACCAGAGTCTTT_p7d_A1': 537,\n",
       " 'ACACCAGATCACGA_p7d_A1': 538,\n",
       " 'ACACCCTGAGCTCA_p7d_A1': 539,\n",
       " 'ACACCCTGAGGTTC_p7d_A1': 540,\n",
       " 'ACACCCTGCACCAA_p7d_A1': 541,\n",
       " 'ACACCCTGGTATCG_p7d_A1': 542,\n",
       " 'ACACCCTGTCAGTG_p7d_A1': 543,\n",
       " 'ACACGAACACCACA_p7d_A1': 544,\n",
       " 'ACACGAACAGACTC_p7d_A1': 545,\n",
       " 'ACACGAACATTCCT_p7d_A1': 546,\n",
       " 'ACACGAACGTTCAG_p7d_A1': 547,\n",
       " 'ACACGATGAGCTAC_p7d_A1': 548,\n",
       " 'ACACGATGCCTATT_p7d_A1': 549,\n",
       " 'ACACGTGAGGTGAG_p7d_A1': 550,\n",
       " 'ACAGACACAGCTAC_p7d_A1': 551,\n",
       " 'ACAGACACCGCTAA_p7d_A1': 552,\n",
       " 'ACAGACACCGTAGT_p7d_A1': 553,\n",
       " 'ACAGCAACAAGTGA_p7d_A1': 554,\n",
       " 'ACAGCAACCGATAC_p7d_A1': 555,\n",
       " 'ACAGCAACCTCATT_p7d_A1': 556,\n",
       " 'ACAGCAACGGAGCA_p7d_A1': 557,\n",
       " 'ACAGGTACACCTTT_p7d_A1': 558,\n",
       " 'ACAGGTACCAGTCA_p7d_A1': 559,\n",
       " 'ACAGGTACCCCTTG_p7d_A1': 560,\n",
       " 'ACAGGTACGAGATA_p7d_A1': 561,\n",
       " 'ACAGGTACGGCGAA_p7d_A1': 562,\n",
       " 'ACAGGTACTAAAGG_p7d_A1': 563,\n",
       " 'ACAGGTACTAGCGT_p7d_A1': 564,\n",
       " 'ACAGGTACTGCTAG_p7d_A1': 565,\n",
       " 'ACAGGTACTTACCT_p7d_A1': 566,\n",
       " 'ACAGTCGAACGCAT_p7d_A1': 567,\n",
       " 'ACAGTCGACATTGG_p7d_A1': 568,\n",
       " 'ACAGTCGACCGATA_p7d_A1': 569,\n",
       " 'ACAGTCGAGACGGA_p7d_A1': 570,\n",
       " 'ACAGTCGATGCCTC_p7d_A1': 571,\n",
       " 'ACAGTGACCGGTAT_p7d_A1': 572,\n",
       " 'ACAGTGACCTACTT_p7d_A1': 573,\n",
       " 'ACAGTGACCTCAGA_p7d_A1': 574,\n",
       " 'ACAGTGACGAAGGC_p7d_A1': 575,\n",
       " 'ACAGTGACGCTATG_p7d_A1': 576,\n",
       " 'ACAGTGACGCTTAG_p7d_A1': 577,\n",
       " 'ACAGTGACGTGTCA_p7d_A1': 578,\n",
       " 'ACAGTGTGAATGCC_p7d_A1': 579,\n",
       " 'ACAGTGTGCTCCCA_p7d_A1': 580,\n",
       " 'ACAGTGTGCTGATG_p7d_A1': 581,\n",
       " 'ACAGTGTGGAGATA_p7d_A1': 582,\n",
       " 'ACAGTGTGTCGTAG_p7d_A1': 583,\n",
       " 'ACAGTTCTACTGTG_p7d_A1': 584,\n",
       " 'ACAGTTCTGCTGAT_p7d_A1': 585,\n",
       " 'ACAGTTCTGTCATG_p7d_A1': 586,\n",
       " 'ACAGTTCTTAGAAG_p7d_A1': 587,\n",
       " 'ACAGTTCTTGCCTC_p7d_A1': 588,\n",
       " 'ACAGTTCTTTCCGC_p7d_A1': 589,\n",
       " 'ACATACCTAAGGGC_p7d_A1': 590,\n",
       " 'ACATACCTACCTAG_p7d_A1': 591,\n",
       " 'ACATACCTAGAATG_p7d_A1': 592,\n",
       " 'ACATACCTGAATAG_p7d_A1': 593,\n",
       " 'ACATACCTTACGCA_p7d_A1': 594,\n",
       " 'ACATACCTTGCCTC_p7d_A1': 595,\n",
       " 'ACATCACTAAGAAC_p7d_A1': 596,\n",
       " 'ACATCACTTGTCAG_p7d_A1': 597,\n",
       " 'ACATGGTGGCCATA_p7d_A1': 598,\n",
       " 'ACATGGTGTCTCAT_p7d_A1': 599,\n",
       " 'ACATGGTGTTCACT_p7d_A1': 600,\n",
       " 'ACATTCTGACCTAG_p7d_A1': 601,\n",
       " 'ACATTCTGATCGTG_p7d_A1': 602,\n",
       " 'ACATTCTGCAAAGA_p7d_A1': 603,\n",
       " 'ACATTCTGCCTCGT_p7d_A1': 604,\n",
       " 'ACATTCTGCCTTGC_p7d_A1': 605,\n",
       " 'ACATTCTGCGTTAG_p7d_A1': 606,\n",
       " 'ACATTCTGCTGTTT_p7d_A1': 607,\n",
       " 'ACATTCTGGTCGTA_p7d_A1': 608,\n",
       " 'ACATTCTGTAGAGA_p7d_A1': 609,\n",
       " 'ACATTCTGTTTACC_p7d_A1': 610,\n",
       " 'ACCAACGAACGCAT_p7d_A1': 611,\n",
       " 'ACCAACGAAGTGTC_p7d_A1': 612,\n",
       " 'ACCAACGACCTCAC_p7d_A1': 613,\n",
       " 'ACCAACGAGGTTTG_p7d_A1': 614,\n",
       " 'ACCAACGATAACGC_p7d_A1': 615,\n",
       " 'ACCACAGAACACTG_p7d_A1': 616,\n",
       " 'ACCACAGAACCACA_p7d_A1': 617,\n",
       " 'ACCACAGACGTTGA_p7d_A1': 618,\n",
       " 'ACCACAGAGCTCCT_p7d_A1': 619,\n",
       " 'ACCACCTGAGTGCT_p7d_A1': 620,\n",
       " 'ACCACCTGAGTTCG_p7d_A1': 621,\n",
       " 'ACCACCTGATAAGG_p7d_A1': 622,\n",
       " 'ACCACCTGATGCCA_p7d_A1': 623,\n",
       " 'ACCACCTGCACTGA_p7d_A1': 624,\n",
       " 'ACCACCTGCCATGA_p7d_A1': 625,\n",
       " 'ACCACCTGCTGTTT_p7d_A1': 626,\n",
       " 'ACCACCTGGTCTGA_p7d_A1': 627,\n",
       " 'ACCACCTGTACAGC_p7d_A1': 628,\n",
       " 'ACCACGCTAAAGCA_p7d_A1': 629,\n",
       " 'ACCACGCTCGCTAA_p7d_A1': 630,\n",
       " 'ACCACGCTGAGACG_p7d_A1': 631,\n",
       " 'ACCACGCTGGTGAG_p7d_A1': 632,\n",
       " 'ACCACGCTGTACCA_p7d_A1': 633,\n",
       " 'ACCACGCTTGCGTA_p7d_A1': 634,\n",
       " 'ACCAGCCTAGCATC_p7d_A1': 635,\n",
       " 'ACCAGCCTCAGATC_p7d_A1': 636,\n",
       " 'ACCAGCCTCCAACA_p7d_A1': 637,\n",
       " 'ACCAGCCTTGTGAC_p7d_A1': 638,\n",
       " 'ACCAGTGAAGCTAC_p7d_A1': 639,\n",
       " 'ACCAGTGATGCTAG_p7d_A1': 640,\n",
       " 'ACCATTACCGCATA_p7d_A1': 641,\n",
       " 'ACCATTACCGTTGA_p7d_A1': 642,\n",
       " 'ACCATTACTCGTTT_p7d_A1': 643,\n",
       " 'ACCATTTGGTAAGA_p7d_A1': 644,\n",
       " 'ACCATTTGGTCTTT_p7d_A1': 645,\n",
       " 'ACCATTTGTGCACA_p7d_A1': 646,\n",
       " 'ACCATTTGTGTAGC_p7d_A1': 647,\n",
       " 'ACCATTTGTTCTCA_p7d_A1': 648,\n",
       " 'ACCCAAGAAAAGCA_p7d_A1': 649,\n",
       " 'ACCCAAGAACACGT_p7d_A1': 650,\n",
       " 'ACCCAAGACCCTTG_p7d_A1': 651,\n",
       " 'ACCCAAGACCTTCG_p7d_A1': 652,\n",
       " 'ACCCAAGATACTGG_p7d_A1': 653,\n",
       " 'ACCCAAGATGTGCA_p7d_A1': 654,\n",
       " 'ACCCACTGACACCA_p7d_A1': 655,\n",
       " 'ACCCACTGAGAACA_p7d_A1': 656,\n",
       " 'ACCCACTGAGTCTG_p7d_A1': 657,\n",
       " 'ACCCACTGCCTTCG_p7d_A1': 658,\n",
       " 'ACCCACTGTACAGC_p7d_A1': 659,\n",
       " 'ACCCACTGTGCTGA_p7d_A1': 660,\n",
       " 'ACCCACTGTTGTGG_p7d_A1': 661,\n",
       " 'ACCCAGCTACCAGT_p7d_A1': 662,\n",
       " 'ACCCAGCTCCCAAA_p7d_A1': 663,\n",
       " 'ACCCGTACAAAAGC_p7d_A1': 664,\n",
       " 'ACCCGTACCCTTGC_p7d_A1': 665,\n",
       " 'ACCCGTACTCCAGA_p7d_A1': 666,\n",
       " 'ACCCGTTGACAGTC_p7d_A1': 667,\n",
       " 'ACCCGTTGCCACCT_p7d_A1': 668,\n",
       " 'ACCCGTTGCCTTGC_p7d_A1': 669,\n",
       " 'ACCCGTTGTCAGTG_p7d_A1': 670,\n",
       " 'ACCCGTTGTGACAC_p7d_A1': 671,\n",
       " 'ACCCGTTGTGAGCT_p7d_A1': 672,\n",
       " 'ACCCGTTGTGTTTC_p7d_A1': 673,\n",
       " 'ACCCGTTGTTCTCA_p7d_A1': 674,\n",
       " 'ACCCTCGAACACCA_p7d_A1': 675,\n",
       " 'ACCCTCGAACACGT_p7d_A1': 676,\n",
       " 'ACCCTCGACAGTCA_p7d_A1': 677,\n",
       " 'ACCCTCGACCAAGT_p7d_A1': 678,\n",
       " 'ACCCTCGAGCAGAG_p7d_A1': 679,\n",
       " 'ACCCTCGATCTTAC_p7d_A1': 680,\n",
       " 'ACCGAAACCACACA_p7d_A1': 681,\n",
       " 'ACCGAAACCACTCC_p7d_A1': 682,\n",
       " 'ACCGAAACGAGCAG_p7d_A1': 683,\n",
       " 'ACCGAAACTGGTCA_p7d_A1': 684,\n",
       " 'ACCGCGGAAACGGG_p7d_A1': 685,\n",
       " 'ACCGCGGAACACAC_p7d_A1': 686,\n",
       " 'ACCGCGGAATTCTC_p7d_A1': 687,\n",
       " 'ACCGCGGACACCAA_p7d_A1': 688,\n",
       " 'ACCGCGGACGGAGA_p7d_A1': 689,\n",
       " 'ACCGCGGACTACGA_p7d_A1': 690,\n",
       " 'ACCGCGGAGGTAAA_p7d_A1': 691,\n",
       " 'ACCGCGGATTCCAT_p7d_A1': 692,\n",
       " 'ACCGTGCTACGGAG_p7d_A1': 693,\n",
       " 'ACCGTGCTGAGGTG_p7d_A1': 694,\n",
       " 'ACCGTGCTGTTTCT_p7d_A1': 695,\n",
       " 'ACCGTGCTTGGTAC_p7d_A1': 696,\n",
       " 'ACCGTGCTTGTCCC_p7d_A1': 697,\n",
       " 'ACCTATTGCCAATG_p7d_A1': 698,\n",
       " 'ACCTATTGGTGTAC_p7d_A1': 699,\n",
       " 'ACCTATTGTGGAAA_p7d_A1': 700,\n",
       " 'ACCTATTGTGTCAG_p7d_A1': 701,\n",
       " 'ACCTCCGAAGTCAC_p7d_A1': 702,\n",
       " 'ACCTCCGAATGGTC_p7d_A1': 703,\n",
       " 'ACCTCCGACACTCC_p7d_A1': 704,\n",
       " 'ACCTCCGAGGCAAG_p7d_A1': 705,\n",
       " 'ACCTCCGAGGTAAA_p7d_A1': 706,\n",
       " 'ACCTCCGAGGTAGG_p7d_A1': 707,\n",
       " 'ACCTCGTGAACGTC_p7d_A1': 708,\n",
       " 'ACCTCGTGTTAGGC_p7d_A1': 709,\n",
       " 'ACCTCGTGTTGCGA_p7d_A1': 710,\n",
       " 'ACCTGAGAATAAGG_p7d_A1': 711,\n",
       " 'ACCTGAGATCCAAG_p7d_A1': 712,\n",
       " 'ACCTGAGATGAACC_p7d_A1': 713,\n",
       " 'ACCTGGCTACCCAA_p7d_A1': 714,\n",
       " 'ACCTGGCTCAGATC_p7d_A1': 715,\n",
       " 'ACCTGGCTTGGTTG_p7d_A1': 716,\n",
       " 'ACCTTTGAATGACC_p7d_A1': 717,\n",
       " 'ACCTTTGACCGAAT_p7d_A1': 718,\n",
       " 'ACCTTTGAGGACGA_p7d_A1': 719,\n",
       " 'ACCTTTGAGTTCGA_p7d_A1': 720,\n",
       " 'ACCTTTGATGGTGT_p7d_A1': 721,\n",
       " 'ACCTTTGATGTGAC_p7d_A1': 722,\n",
       " 'ACCTTTGATTCGGA_p7d_A1': 723,\n",
       " 'ACGAACACACTGTG_p7d_A1': 724,\n",
       " 'ACGAACACCCTGAA_p7d_A1': 725,\n",
       " 'ACGAACTGCATTTC_p7d_A1': 726,\n",
       " 'ACGAACTGCCTCGT_p7d_A1': 727,\n",
       " 'ACGAACTGCGTTGA_p7d_A1': 728,\n",
       " 'ACGAACTGCTCCAC_p7d_A1': 729,\n",
       " 'ACGAACTGTTTGGG_p7d_A1': 730,\n",
       " 'ACGAAGCTAAGATG_p7d_A1': 731,\n",
       " 'ACGAAGCTACCTCC_p7d_A1': 732,\n",
       " 'ACGAAGCTATGGTC_p7d_A1': 733,\n",
       " 'ACGAAGCTCAACCA_p7d_A1': 734,\n",
       " 'ACGAAGCTCTCTAT_p7d_A1': 735,\n",
       " 'ACGAAGCTGACGAG_p7d_A1': 736,\n",
       " 'ACGAAGCTGAGCTT_p7d_A1': 737,\n",
       " 'ACGAAGCTGTAGGG_p7d_A1': 738,\n",
       " 'ACGAAGCTGTGTAC_p7d_A1': 739,\n",
       " 'ACGAAGCTGTTCGA_p7d_A1': 740,\n",
       " 'ACGACAACAGTGCT_p7d_A1': 741,\n",
       " 'ACGACAACATGCCA_p7d_A1': 742,\n",
       " 'ACGACAACATTCGG_p7d_A1': 743,\n",
       " 'ACGACAACGTAGGG_p7d_A1': 744,\n",
       " 'ACGACAACTGCCCT_p7d_A1': 745,\n",
       " 'ACGACCCTAAGAGT_p7d_A1': 746,\n",
       " 'ACGACCCTACTAGC_p7d_A1': 747,\n",
       " 'ACGACCCTAGAACA_p7d_A1': 748,\n",
       " 'ACGACCCTTTGGTG_p7d_A1': 749,\n",
       " 'ACGAGGGAAGCAAA_p7d_A1': 750,\n",
       " 'ACGAGGGAGGGCAA_p7d_A1': 751,\n",
       " 'ACGAGGGATGGTTG_p7d_A1': 752,\n",
       " 'ACGAGGGATGTGCA_p7d_A1': 753,\n",
       " 'ACGAGGGATTATCC_p7d_A1': 754,\n",
       " 'ACGAGTACACACAC_p7d_A1': 755,\n",
       " 'ACGAGTACGGACGA_p7d_A1': 756,\n",
       " 'ACGAGTACGTTACG_p7d_A1': 757,\n",
       " 'ACGAGTACGTTCGA_p7d_A1': 758,\n",
       " 'ACGAGTACTTGCTT_p7d_A1': 759,\n",
       " 'ACGATCGAACGCTA_p7d_A1': 760,\n",
       " 'ACGATCGAGAGGCA_p7d_A1': 761,\n",
       " 'ACGATCGATCCTTA_p7d_A1': 762,\n",
       " 'ACGATCGATCTCGC_p7d_A1': 763,\n",
       " 'ACGATCGATGACAC_p7d_A1': 764,\n",
       " 'ACGATCGATGGAGG_p7d_A1': 765,\n",
       " 'ACGATCGATTCAGG_p7d_A1': 766,\n",
       " 'ACGATGACAAGAAC_p7d_A1': 767,\n",
       " 'ACGATGACACCGAT_p7d_A1': 768,\n",
       " 'ACGATGACCCTTCG_p7d_A1': 769,\n",
       " 'ACGATGACGCCCTT_p7d_A1': 770,\n",
       " 'ACGATGACTTCGGA_p7d_A1': 771,\n",
       " 'ACGATTCTCACTTT_p7d_A1': 772,\n",
       " 'ACGATTCTTCGATG_p7d_A1': 773,\n",
       " 'ACGATTCTTTCTCA_p7d_A1': 774,\n",
       " 'ACGCAATGAACCAC_p7d_A1': 775,\n",
       " 'ACGCACCTGTCACA_p7d_A1': 776,\n",
       " 'ACGCACCTTCTTCA_p7d_A1': 777,\n",
       " 'ACGCACCTTCTTTG_p7d_A1': 778,\n",
       " 'ACGCCACTTCCTAT_p7d_A1': 779,\n",
       " 'ACGCCACTTCTCAT_p7d_A1': 780,\n",
       " 'ACGCCACTTGCATG_p7d_A1': 781,\n",
       " 'ACGCCGGACACTCC_p7d_A1': 782,\n",
       " 'ACGCCGGACCGTAA_p7d_A1': 783,\n",
       " 'ACGCCGGAGTACGT_p7d_A1': 784,\n",
       " 'ACGCCGGAGTTCAG_p7d_A1': 785,\n",
       " 'ACGCCGGAGTTCGA_p7d_A1': 786,\n",
       " 'ACGCCTTGCAACCA_p7d_A1': 787,\n",
       " 'ACGCCTTGCTACCC_p7d_A1': 788,\n",
       " 'ACGCCTTGGACAGG_p7d_A1': 789,\n",
       " 'ACGCCTTGGTGTTG_p7d_A1': 790,\n",
       " 'ACGCCTTGTCCCAC_p7d_A1': 791,\n",
       " 'ACGCGGTGCTTCGC_p7d_A1': 792,\n",
       " 'ACGCGGTGGTACAC_p7d_A1': 793,\n",
       " 'ACGCGGTGTAAGGA_p7d_A1': 794,\n",
       " 'ACGCGGTGTCCGAA_p7d_A1': 795,\n",
       " 'ACGCGGTGTCTCAT_p7d_A1': 796,\n",
       " 'ACGCGGTGTGCCCT_p7d_A1': 797,\n",
       " 'ACGCGGTGTTCTTG_p7d_A1': 798,\n",
       " 'ACGCTCACACACTG_p7d_A1': 799,\n",
       " 'ACGCTCACACCTGA_p7d_A1': 800,\n",
       " 'ACGCTCACCCGTTC_p7d_A1': 801,\n",
       " 'ACGCTCACCCTTTA_p7d_A1': 802,\n",
       " 'ACGCTCACCGCCTT_p7d_A1': 803,\n",
       " 'ACGCTCACCTTAGG_p7d_A1': 804,\n",
       " 'ACGCTCACGGACGA_p7d_A1': 805,\n",
       " 'ACGCTGCTAAACAG_p7d_A1': 806,\n",
       " 'ACGCTGCTAGTGCT_p7d_A1': 807,\n",
       " 'ACGCTGCTGTATGC_p7d_A1': 808,\n",
       " 'ACGCTGCTTATCGG_p7d_A1': 809,\n",
       " 'ACGGAACTAAACAG_p7d_A1': 810,\n",
       " 'ACGGAACTTCGCCT_p7d_A1': 811,\n",
       " 'ACGGAGGACTGTTT_p7d_A1': 812,\n",
       " 'ACGGAGGAGCGATT_p7d_A1': 813,\n",
       " 'ACGGAGGAGTTGCA_p7d_A1': 814,\n",
       " 'ACGGAGGATAAGCC_p7d_A1': 815,\n",
       " 'ACGGAGGATCCGAA_p7d_A1': 816,\n",
       " 'ACGGATTGATCGAC_p7d_A1': 817,\n",
       " 'ACGGATTGCCTTCG_p7d_A1': 818,\n",
       " 'ACGGATTGCGAGTT_p7d_A1': 819,\n",
       " 'ACGGATTGGACGGA_p7d_A1': 820,\n",
       " 'ACGGATTGGCAGTT_p7d_A1': 821,\n",
       " 'ACGGATTGGTAAAG_p7d_A1': 822,\n",
       " 'ACGGCGTGATTCCT_p7d_A1': 823,\n",
       " 'ACGGCGTGCCAGTA_p7d_A1': 824,\n",
       " 'ACGGCGTGGAACCT_p7d_A1': 825,\n",
       " 'ACGGCGTGGAATAG_p7d_A1': 826,\n",
       " 'ACGGCGTGGGAGCA_p7d_A1': 827,\n",
       " 'ACGGCGTGTTCTGT_p7d_A1': 828,\n",
       " 'ACGGCTCTAAACAG_p7d_A1': 829,\n",
       " 'ACGGCTCTAGAATG_p7d_A1': 830,\n",
       " 'ACGGCTCTAGCGGA_p7d_A1': 831,\n",
       " 'ACGGGAGAATTGGC_p7d_A1': 832,\n",
       " 'ACGGGAGAGCTATG_p7d_A1': 833,\n",
       " 'ACGGGAGAGTATCG_p7d_A1': 834,\n",
       " 'ACGGGAGATCTTTG_p7d_A1': 835,\n",
       " 'ACGGTAACGAGGAC_p7d_A1': 836,\n",
       " 'ACGGTAACTAAGGA_p7d_A1': 837,\n",
       " 'ACGGTAACTCCCAC_p7d_A1': 838,\n",
       " 'ACGGTATGCCTTTA_p7d_A1': 839,\n",
       " 'ACGGTATGCTATTC_p7d_A1': 840,\n",
       " 'ACGGTATGTAGACC_p7d_A1': 841,\n",
       " 'ACGGTATGTCCAAG_p7d_A1': 842,\n",
       " 'ACGGTATGTCCTCG_p7d_A1': 843,\n",
       " 'ACGGTATGTCCTTA_p7d_A1': 844,\n",
       " 'ACGGTATGTTTGTC_p7d_A1': 845,\n",
       " 'ACGGTCCTCATGGT_p7d_A1': 846,\n",
       " 'ACGGTCCTCTCGAA_p7d_A1': 847,\n",
       " 'ACGGTCCTGCAGTT_p7d_A1': 848,\n",
       " 'ACGGTCCTGCGTTA_p7d_A1': 849,\n",
       " 'ACGGTCCTTAAGCC_p7d_A1': 850,\n",
       " 'ACGGTCCTTACTCT_p7d_A1': 851,\n",
       " 'ACGGTCCTTAGCGT_p7d_A1': 852,\n",
       " 'ACGGTCCTTGGGAG_p7d_A1': 853,\n",
       " 'ACGTAGACACCGAT_p7d_A1': 854,\n",
       " 'ACGTAGACACGGGA_p7d_A1': 855,\n",
       " 'ACGTAGACACTACG_p7d_A1': 856,\n",
       " 'ACGTAGACACTAGC_p7d_A1': 857,\n",
       " 'ACGTAGACAGGTCT_p7d_A1': 858,\n",
       " 'ACGTAGACAGGTTC_p7d_A1': 859,\n",
       " 'ACGTAGACCAGGAG_p7d_A1': 860,\n",
       " 'ACGTAGACCATGGT_p7d_A1': 861,\n",
       " 'ACGTAGACCCCACT_p7d_A1': 862,\n",
       " 'ACGTAGACCTCATT_p7d_A1': 863,\n",
       " 'ACGTAGACCTGTTT_p7d_A1': 864,\n",
       " 'ACGTCAGAAATGCC_p7d_A1': 865,\n",
       " 'ACGTCAGACTTCGC_p7d_A1': 866,\n",
       " 'ACGTCAGAGCAGTT_p7d_A1': 867,\n",
       " 'ACGTCCTGAAACAG_p7d_A1': 868,\n",
       " 'ACGTCCTGAACCAC_p7d_A1': 869,\n",
       " 'ACGTCCTGATCTCT_p7d_A1': 870,\n",
       " 'ACGTCCTGCCAAGT_p7d_A1': 871,\n",
       " 'ACGTCCTGGTTCAG_p7d_A1': 872,\n",
       " 'ACGTCCTGTGGAGG_p7d_A1': 873,\n",
       " 'ACGTCGCTCAACCA_p7d_A1': 874,\n",
       " 'ACGTCGCTCGAGTT_p7d_A1': 875,\n",
       " 'ACGTCGCTCGGGAA_p7d_A1': 876,\n",
       " 'ACGTCGCTGCTTCC_p7d_A1': 877,\n",
       " 'ACGTCGCTTCAGGT_p7d_A1': 878,\n",
       " 'ACGTCGCTTCCCAC_p7d_A1': 879,\n",
       " 'ACGTCGCTTGAACC_p7d_A1': 880,\n",
       " 'ACGTGATGAACGAA_p7d_A1': 881,\n",
       " 'ACGTGATGCTGCTC_p7d_A1': 882,\n",
       " 'ACGTGATGGATAAG_p7d_A1': 883,\n",
       " 'ACGTGATGGTCACA_p7d_A1': 884,\n",
       " 'ACGTGATGGTGAGG_p7d_A1': 885,\n",
       " 'ACGTGATGTGCAAC_p7d_A1': 886,\n",
       " 'ACGTGCCTAAAAGC_p7d_A1': 887,\n",
       " 'ACGTGCCTCTGACA_p7d_A1': 888,\n",
       " 'ACGTGCCTGGTCAT_p7d_A1': 889,\n",
       " 'ACGTGCCTTCGCAA_p7d_A1': 890,\n",
       " 'ACGTGCCTTCTATC_p7d_A1': 891,\n",
       " 'ACGTGCCTTTAGGC_p7d_A1': 892,\n",
       " 'ACGTTACTACGGGA_p7d_A1': 893,\n",
       " 'ACGTTACTGCGTTA_p7d_A1': 894,\n",
       " 'ACGTTGGAAACAGA_p7d_A1': 895,\n",
       " 'ACGTTGGACAAGCT_p7d_A1': 896,\n",
       " 'ACGTTGGACTCTCG_p7d_A1': 897,\n",
       " 'ACGTTGGAGACGTT_p7d_A1': 898,\n",
       " 'ACGTTGGAGTTAGC_p7d_A1': 899,\n",
       " 'ACGTTGGATTCTAC_p7d_A1': 900,\n",
       " 'ACGTTTACACCAGT_p7d_A1': 901,\n",
       " 'ACGTTTACCCACAA_p7d_A1': 902,\n",
       " 'ACGTTTACCTGCTC_p7d_A1': 903,\n",
       " 'ACGTTTACGAAGGC_p7d_A1': 904,\n",
       " 'ACGTTTACGAATGA_p7d_A1': 905,\n",
       " 'ACGTTTACTACAGC_p7d_A1': 906,\n",
       " 'ACTAAAACCGGAGA_p7d_A1': 907,\n",
       " 'ACTAAAACGAAGGC_p7d_A1': 908,\n",
       " 'ACTAAAACTCTAGG_p7d_A1': 909,\n",
       " 'ACTAAAACTCTCTA_p7d_A1': 910,\n",
       " 'ACTACGGACCACCT_p7d_A1': 911,\n",
       " 'ACTACGGATCCCGT_p7d_A1': 912,\n",
       " 'ACTACGGATGCTAG_p7d_A1': 913,\n",
       " 'ACTACTACATGTGC_p7d_A1': 914,\n",
       " 'ACTACTACCAAAGA_p7d_A1': 915,\n",
       " 'ACTACTACGGTAGG_p7d_A1': 916,\n",
       " 'ACTAGGTGCGACTA_p7d_A1': 917,\n",
       " 'ACTAGGTGTTTACC_p7d_A1': 918,\n",
       " 'ACTATCACATACCG_p7d_A1': 919,\n",
       " 'ACTATCACCTGTAG_p7d_A1': 920,\n",
       " 'ACTATCACGACGTT_p7d_A1': 921,\n",
       " 'ACTATCACGTCCTC_p7d_A1': 922,\n",
       " 'ACTATCACGTGTTG_p7d_A1': 923,\n",
       " 'ACTATCACTATCTC_p7d_A1': 924,\n",
       " 'ACTCAGGAGTACGT_p7d_A1': 925,\n",
       " 'ACTCAGGATGCTAG_p7d_A1': 926,\n",
       " 'ACTCAGGATGTGGT_p7d_A1': 927,\n",
       " 'ACTCCCGAATGCCA_p7d_A1': 928,\n",
       " 'ACTCCCGACTACGA_p7d_A1': 929,\n",
       " 'ACTCCCGAGTGAGG_p7d_A1': 930,\n",
       " 'ACTCCCGATCCTCG_p7d_A1': 931,\n",
       " 'ACTCCTCTAAGGCG_p7d_A1': 932,\n",
       " 'ACTCCTCTACACAC_p7d_A1': 933,\n",
       " 'ACTCCTCTAGCGTT_p7d_A1': 934,\n",
       " 'ACTCCTCTATGTCG_p7d_A1': 935,\n",
       " 'ACTCCTCTCCTTGC_p7d_A1': 936,\n",
       " 'ACTCCTCTGGATTC_p7d_A1': 937,\n",
       " 'ACTCGCACCGCAAT_p7d_A1': 938,\n",
       " 'ACTCGCACGTATGC_p7d_A1': 939,\n",
       " 'ACTCGCACTAGAGA_p7d_A1': 940,\n",
       " 'ACTCTATGCATACG_p7d_A1': 941,\n",
       " 'ACTCTATGGAGGTG_p7d_A1': 942,\n",
       " 'ACTCTATGGGGTGA_p7d_A1': 943,\n",
       " 'ACTCTCCTTTCTAC_p7d_A1': 944,\n",
       " 'ACTGAGACACGCTA_p7d_A1': 945,\n",
       " 'ACTGAGACATCGTG_p7d_A1': 946,\n",
       " 'ACTGAGACCTCAGA_p7d_A1': 947,\n",
       " 'ACTGAGACCTTGGA_p7d_A1': 948,\n",
       " 'ACTGAGACGCTCCT_p7d_A1': 949,\n",
       " 'ACTGAGACGGTCAT_p7d_A1': 950,\n",
       " 'ACTGAGACGTGCAT_p7d_A1': 951,\n",
       " 'ACTGAGACTTCATC_p7d_A1': 952,\n",
       " 'ACTGCCACACACCA_p7d_A1': 953,\n",
       " 'ACTGCCACACCAGT_p7d_A1': 954,\n",
       " 'ACTGCCACCCTATT_p7d_A1': 955,\n",
       " 'ACTGCCACCGCAAT_p7d_A1': 956,\n",
       " 'ACTGCCACGGAGTG_p7d_A1': 957,\n",
       " 'ACTGCCACGTCACA_p7d_A1': 958,\n",
       " 'ACTGCCACTACTGG_p7d_A1': 959,\n",
       " 'ACTGCCACTGGTCA_p7d_A1': 960,\n",
       " 'ACTGCCTGAAGCCT_p7d_A1': 961,\n",
       " 'ACTGCCTGATCTCT_p7d_A1': 962,\n",
       " 'ACTGCCTGCGATAC_p7d_A1': 963,\n",
       " 'ACTGCCTGCTACTT_p7d_A1': 964,\n",
       " 'ACTGCCTGTGCACA_p7d_A1': 965,\n",
       " 'ACTGGCCTAACTGC_p7d_A1': 966,\n",
       " 'ACTGGCCTAAGGCG_p7d_A1': 967,\n",
       " 'ACTGGCCTACCTCC_p7d_A1': 968,\n",
       " 'ACTGGCCTATGCTG_p7d_A1': 969,\n",
       " 'ACTGGCCTCTCTAT_p7d_A1': 970,\n",
       " 'ACTGGCCTCTGAGT_p7d_A1': 971,\n",
       " 'ACTGGCCTTGAGAA_p7d_A1': 972,\n",
       " 'ACTGTGGAAAAGCA_p7d_A1': 973,\n",
       " 'ACTGTGGAAAGGGC_p7d_A1': 974,\n",
       " 'ACTGTGGAAAGTGA_p7d_A1': 975,\n",
       " 'ACTGTGGACTGATG_p7d_A1': 976,\n",
       " 'ACTGTGGATGCTCC_p7d_A1': 977,\n",
       " 'ACTGTGGATGTGAC_p7d_A1': 978,\n",
       " 'ACTGTTACCTCGCT_p7d_A1': 979,\n",
       " 'ACTGTTACGACTAC_p7d_A1': 980,\n",
       " 'ACTGTTACGAGATA_p7d_A1': 981,\n",
       " 'ACTGTTACGCAAGG_p7d_A1': 982,\n",
       " 'ACTGTTACGTTCGA_p7d_A1': 983,\n",
       " 'ACTGTTACTCCTAT_p7d_A1': 984,\n",
       " 'ACTTAAGACTCCCA_p7d_A1': 985,\n",
       " 'ACTTAAGATGCACA_p7d_A1': 986,\n",
       " 'ACTTAGCTATCACG_p7d_A1': 987,\n",
       " 'ACTTAGCTATTCCT_p7d_A1': 988,\n",
       " 'ACTTAGCTGATAGA_p7d_A1': 989,\n",
       " 'ACTTAGCTGCATCA_p7d_A1': 990,\n",
       " 'ACTTCAACCTAGCA_p7d_A1': 991,\n",
       " 'ACTTCAACCTTACT_p7d_A1': 992,\n",
       " 'ACTTCAACCTTCTA_p7d_A1': 993,\n",
       " 'ACTTCCCTAACGAA_p7d_A1': 994,\n",
       " 'ACTTCCCTCAGAAA_p7d_A1': 995,\n",
       " 'ACTTCCCTTAACGC_p7d_A1': 996,\n",
       " 'ACTTCCCTTCATTC_p7d_A1': 997,\n",
       " 'ACTTCTGAGAGCTT_p7d_A1': 998,\n",
       " 'ACTTCTGATCGTAG_p7d_A1': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['condition'] = pd.NA\n",
    "for cell_id in adata.obs.index:\n",
    "    if cell_id in perturb_series.index:\n",
    "        adata.obs.at[cell_id, 'condition'] = perturb_series[cell_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_names</th>\n",
       "      <th>condition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_names</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAACATACGCTACA_p7d_A1</th>\n",
       "      <td>AAACATACGCTACA_p7d_A1</td>\n",
       "      <td>p_sgELK1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACATACTCCTGC_p7d_A1</th>\n",
       "      <td>AAACATACTCCTGC_p7d_A1</td>\n",
       "      <td>p_sgELF1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACATTGACGTTG_p7d_A1</th>\n",
       "      <td>AAACATTGACGTTG_p7d_A1</td>\n",
       "      <td>p_sgELF1_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACATTGATTCGG_p7d_A1</th>\n",
       "      <td>AAACATTGATTCGG_p7d_A1</td>\n",
       "      <td>p_sgELF1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACATTGGAGCAG_p7d_A1</th>\n",
       "      <td>AAACATTGGAGCAG_p7d_A1</td>\n",
       "      <td>p_sgELK1_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGACTGTGCGTA_p7d_C2</th>\n",
       "      <td>TTTGACTGTGCGTA_p7d_C2</td>\n",
       "      <td>p_sgETS1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGCATGAGAGGC_p7d_C2</th>\n",
       "      <td>TTTGCATGAGAGGC_p7d_C2</td>\n",
       "      <td>p_INTERGENIC216151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGCATGAGCTAC_p7d_C2</th>\n",
       "      <td>TTTGCATGAGCTAC_p7d_C2</td>\n",
       "      <td>p_INTERGENIC1216445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGCATGCCGCTT_p7d_C2</th>\n",
       "      <td>TTTGCATGCCGCTT_p7d_C2</td>\n",
       "      <td>p_sgCREB1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGCATGCGTAGT_p7d_C2</th>\n",
       "      <td>TTTGCATGCGTAGT_p7d_C2</td>\n",
       "      <td>p_sgETS1_5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33013 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  cell_names            condition\n",
       "cell_names                                                       \n",
       "AAACATACGCTACA_p7d_A1  AAACATACGCTACA_p7d_A1           p_sgELK1_1\n",
       "AAACATACTCCTGC_p7d_A1  AAACATACTCCTGC_p7d_A1           p_sgELF1_2\n",
       "AAACATTGACGTTG_p7d_A1  AAACATTGACGTTG_p7d_A1           p_sgELF1_5\n",
       "AAACATTGATTCGG_p7d_A1  AAACATTGATTCGG_p7d_A1           p_sgELF1_2\n",
       "AAACATTGGAGCAG_p7d_A1  AAACATTGGAGCAG_p7d_A1           p_sgELK1_7\n",
       "...                                      ...                  ...\n",
       "TTTGACTGTGCGTA_p7d_C2  TTTGACTGTGCGTA_p7d_C2           p_sgETS1_3\n",
       "TTTGCATGAGAGGC_p7d_C2  TTTGCATGAGAGGC_p7d_C2   p_INTERGENIC216151\n",
       "TTTGCATGAGCTAC_p7d_C2  TTTGCATGAGCTAC_p7d_C2  p_INTERGENIC1216445\n",
       "TTTGCATGCCGCTT_p7d_C2  TTTGCATGCCGCTT_p7d_C2          p_sgCREB1_4\n",
       "TTTGCATGCGTAGT_p7d_C2  TTTGCATGCGTAGT_p7d_C2           p_sgETS1_5\n",
       "\n",
       "[33013 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsetting the dataset\n",
    "# adata = adata[:5000, :]\n",
    "\n",
    "# preprocessing\n",
    "# suggested preprocessing according to https://github.com/snap-stanford/GEARS/blob/master/demo/data_tutorial.ipynb\n",
    "sc.pp.normalize_total(adata)\n",
    "sc.pp.log1p(adata)\n",
    "\n",
    "# SUBSETTING\n",
    "sc.pp.highly_variable_genes(adata, n_top_genes=200, subset=True)\n",
    "\n",
    "# # Renaming 'perturbation_name' to 'condition' in adata.obs\n",
    "# adata.obs.rename(columns={'perturbation_name': 'condition'}, inplace=True)\n",
    "\n",
    "# # gene symbol is being read as an index but needed as column for the analysis\n",
    "# adata.var.reset_index(inplace=True)\n",
    "\n",
    "# # rename to 'gene_name' bc pert_data() calls for it\n",
    "# adata.var.rename(columns={'gene_symbols' : 'gene_name'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[\"cell_type\"] ='K562'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with NA in 'condition' column\n",
    "no_na_adata = adata[adata.obs['condition'].notnull()].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in .obs: True\n",
      "Missing values in .var: False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Check for any NA values in adata.obs\n",
    "obs_na = adata.obs.isna().any().any()\n",
    "# This checks for any NA values in the entire .obs dataframe. \n",
    "# The first .any() reduces it to a per-column check, and the second .any() checks if any of those are True.\n",
    "\n",
    "# Check for any NA values in adata.var\n",
    "var_na = adata.var.isna().any().any()\n",
    "# Similar to above, for the .var dataframe.\n",
    "\n",
    "print(f\"Missing values in .obs: {obs_na}\")\n",
    "print(f\"Missing values in .var: {var_na}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values: []\n"
     ]
    }
   ],
   "source": [
    "missing_value_columns = no_na_adata.obs.columns[no_na_adata.obs.isnull().any()].tolist()\n",
    "print(\"Columns with missing values:\", missing_value_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs  n_vars = 27391  200\n",
       "    obs: 'cell_names', 'condition', 'cell_type'\n",
       "    var: 'gene_name', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
       "    uns: 'log1p', 'hvg'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_na_adata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values in .X\n"
     ]
    }
   ],
   "source": [
    "# Convert .X to a dense format if it's stored as a sparse matrix, then check for NA\n",
    "if pd.isna(adata.X.data).any():\n",
    "    print(\"There are missing values in .X\")\n",
    "else:\n",
    "    print(\"No missing values in .X\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings for data prcocessing\n",
    "pad_token = \"<pad>\"\n",
    "special_tokens = [pad_token, \"<cls>\", \"<eoc>\"]\n",
    "pad_value = 0  # for padding values\n",
    "pert_pad_id = 2\n",
    "\n",
    "n_hvg = 0  # number of highly variable genes\n",
    "include_zero_gene = \"all\"  # include zero expr genes in training input, \"all\", \"batch-wise\", \"row-wise\", or False\n",
    "max_seq_len = 1536\n",
    "\n",
    "# settings for training\n",
    "MLM = True  # whether to use masked language modeling, currently it is always on.\n",
    "CLS = False  # celltype classification objective\n",
    "CCE = False  # Contrastive cell embedding objective\n",
    "MVC = False  # Masked value prediction for cell embedding\n",
    "ECS = False  # Elastic cell similarity objective\n",
    "cell_emb_style = \"cls\"\n",
    "mvc_decoder_style = \"inner product, detach\"\n",
    "amp = True\n",
    "load_model = \"../save/scGPT_human\"\n",
    "load_param_prefixs = [\n",
    "    \"encoder\",\n",
    "    \"value_encoder\",\n",
    "    \"transformer_encoder\",\n",
    "]\n",
    "\n",
    "# settings for optimizer\n",
    "lr = 1e-4  # or 1e-4\n",
    "batch_size = 32\n",
    "eval_batch_size = 32\n",
    "epochs = 2\n",
    "schedule_interval = 1\n",
    "early_stop = 5\n",
    "\n",
    "# settings for the model\n",
    "embsize = 512  # embedding dimension\n",
    "d_hid = 512  # dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 12  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 8  # number of heads in nn.MultiheadAttention\n",
    "n_layers_cls = 3\n",
    "dropout = 0.2  # dropout probability\n",
    "use_fast_transformer = True  # whether to use fast transformer\n",
    "\n",
    "# logging\n",
    "log_interval = 100\n",
    "\n",
    "# dataset and evaluation choices\n",
    "data_name = \"dixit\"\n",
    "split = \"simulation\"\n",
    "# if data_name == \"norman\":\n",
    "#     perts_to_plot = [\"SAMD1+ZBTB1\"]\n",
    "# elif data_name == \"adamson\":\n",
    "#     perts_to_plot = [\"KCTD16+ctrl\"]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K562_p_sgELK1_1_1' 'K562_p_sgELF1_2_1' 'K562_p_sgELF1_5_1'\n",
      " 'K562_p_sgELK1_7_1' 'K562_p_sgIRF1_2_1' 'K562_p_sgETS1_5_1'\n",
      " 'K562_p_INTERGENIC216151_1' 'K562_p_sgEGR1_4_1'\n",
      " 'K562_p_INTERGENIC393453_1' 'K562_p_sgYY1_3_1' 'K562_p_sgETS1_3_1'\n",
      " 'K562_p_sgELK1_6_1' 'K562_p_sgGABPA_1_1' 'K562_p_sgE2F4_7_1'\n",
      " 'K562_p_sgNR2C2_5_1' 'K562_p_sgCREB1_2_1' 'K562_p_INTERGENIC1216445_1'\n",
      " 'K562_p_sgNR2C2_2_1' 'K562_p_sgCREB1_5_1' 'K562_p_INTERGENIC1144056_1'\n",
      " 'K562_p_sgELF1_1_1' 'K562_p_sgIRF1_3_1' 'K562_p_sgEGR1_2_1'\n",
      " 'K562_p_sgYY1_10_1' 'K562_p_sgGABPA_9_1' 'K562_p_sgCREB1_4_1'\n",
      " 'K562_p_sgNR2C2_3_1' 'K562_p_sgE2F4_6_1' 'K562_p_sgELF1_4_1']\n"
     ]
    }
   ],
   "source": [
    "print(no_na_adata.obs['condition_name'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "reference = K562_ctrl_1 needs to be one of groupby = ['K562_p_INTERGENIC216151_1', 'K562_p_INTERGENIC393453_1', 'K562_p_INTERGENIC1144056_1', 'K562_p_INTERGENIC1216445_1', 'K562_p_sgCREB1_2_1', 'K562_p_sgCREB1_4_1', 'K562_p_sgCREB1_5_1', 'K562_p_sgE2F4_6_1', 'K562_p_sgE2F4_7_1', 'K562_p_sgEGR1_2_1', 'K562_p_sgEGR1_4_1', 'K562_p_sgELF1_1_1', 'K562_p_sgELF1_2_1', 'K562_p_sgELF1_4_1', 'K562_p_sgELF1_5_1', 'K562_p_sgELK1_1_1', 'K562_p_sgELK1_6_1', 'K562_p_sgELK1_7_1', 'K562_p_sgETS1_3_1', 'K562_p_sgETS1_5_1', 'K562_p_sgGABPA_1_1', 'K562_p_sgGABPA_9_1', 'K562_p_sgIRF1_2_1', 'K562_p_sgIRF1_3_1', 'K562_p_sgNR2C2_2_1', 'K562_p_sgNR2C2_3_1', 'K562_p_sgNR2C2_5_1', 'K562_p_sgYY1_3_1', 'K562_p_sgYY1_10_1'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/bench-user/perturbation_model/tutorials/Perturbation_Prediction.ipynb Cell 25\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://code-server-protective-parrot-ajf.us-west-2.aws.bench.deeporigin.io/home/bench-user/perturbation_model/tutorials/Perturbation_Prediction.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m pert_data \u001b[39m=\u001b[39m PertData(\u001b[39m\"\u001b[39m\u001b[39m./data\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://code-server-protective-parrot-ajf.us-west-2.aws.bench.deeporigin.io/home/bench-user/perturbation_model/tutorials/Perturbation_Prediction.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m pert_data\u001b[39m.\u001b[39;49mnew_data_process(dataset_name \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mdixit\u001b[39;49m\u001b[39m\"\u001b[39;49m, adata \u001b[39m=\u001b[39;49m no_na_adata)\n\u001b[1;32m      <a href='vscode-notebook-cell://code-server-protective-parrot-ajf.us-west-2.aws.bench.deeporigin.io/home/bench-user/perturbation_model/tutorials/Perturbation_Prediction.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m pert_data\u001b[39m.\u001b[39mload(data_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./data/dixit\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m# load the processed data, path is saved folder + dataset name\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://code-server-protective-parrot-ajf.us-west-2.aws.bench.deeporigin.io/home/bench-user/perturbation_model/tutorials/Perturbation_Prediction.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m pert_data\u001b[39m.\u001b[39mprepare_split(split\u001b[39m=\u001b[39msplit, seed\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.apps/conda/envs/rtd/lib/python3.9/site-packages/gears/pertdata.py:85\u001b[0m, in \u001b[0;36mPertData.new_data_process\u001b[0;34m(self, dataset_name, adata)\u001b[0m\n\u001b[1;32m     83\u001b[0m     os\u001b[39m.\u001b[39mmkdir(save_data_folder)\n\u001b[1;32m     84\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_path \u001b[39m=\u001b[39m save_data_folder\n\u001b[0;32m---> 85\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madata \u001b[39m=\u001b[39m get_DE_genes(adata)\n\u001b[1;32m     86\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madata \u001b[39m=\u001b[39m get_dropout_non_zero_genes(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39madata)\n\u001b[1;32m     87\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madata\u001b[39m.\u001b[39mwrite_h5ad(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(save_data_folder, \u001b[39m'\u001b[39m\u001b[39mperturb_processed.h5ad\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[0;32m~/.apps/conda/envs/rtd/lib/python3.9/site-packages/gears/data_utils.py:61\u001b[0m, in \u001b[0;36mget_DE_genes\u001b[0;34m(adata)\u001b[0m\n\u001b[1;32m     59\u001b[0m adata\u001b[39m.\u001b[39mobs\u001b[39m.\u001b[39mloc[:, \u001b[39m'\u001b[39m\u001b[39mcontrol\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m adata\u001b[39m.\u001b[39mobs\u001b[39m.\u001b[39mcondition\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(x\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m)) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m)\n\u001b[1;32m     60\u001b[0m adata\u001b[39m.\u001b[39mobs\u001b[39m.\u001b[39mloc[:, \u001b[39m'\u001b[39m\u001b[39mcondition_name\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m  adata\u001b[39m.\u001b[39mobs\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([x\u001b[39m.\u001b[39mcell_type, x\u001b[39m.\u001b[39mcondition, x\u001b[39m.\u001b[39mdose_val]), axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m) \n\u001b[0;32m---> 61\u001b[0m rank_genes_groups_by_cov(adata, \n\u001b[1;32m     62\u001b[0m                      groupby\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcondition_name\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m     63\u001b[0m                      covariate\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcell_type\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m     64\u001b[0m                      control_group\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mctrl_1\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m     65\u001b[0m                      n_genes\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(adata\u001b[39m.\u001b[39;49mvar),\n\u001b[1;32m     66\u001b[0m                      key_added \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mrank_genes_groups_cov_all\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     67\u001b[0m \u001b[39mreturn\u001b[39;00m adata\n",
      "File \u001b[0;32m~/.apps/conda/envs/rtd/lib/python3.9/site-packages/gears/data_utils.py:37\u001b[0m, in \u001b[0;36mrank_genes_groups_by_cov\u001b[0;34m(adata, groupby, control_group, covariate, pool_doses, n_genes, rankby_abs, key_added, return_dict)\u001b[0m\n\u001b[1;32m     34\u001b[0m adata_cov \u001b[39m=\u001b[39m adata[adata\u001b[39m.\u001b[39mobs[covariate]\u001b[39m==\u001b[39mcov_cat]\n\u001b[1;32m     36\u001b[0m \u001b[39m#compute DEGs\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m sc\u001b[39m.\u001b[39;49mtl\u001b[39m.\u001b[39;49mrank_genes_groups(\n\u001b[1;32m     38\u001b[0m     adata_cov,\n\u001b[1;32m     39\u001b[0m     groupby\u001b[39m=\u001b[39;49mgroupby,\n\u001b[1;32m     40\u001b[0m     reference\u001b[39m=\u001b[39;49mcontrol_group_cov,\n\u001b[1;32m     41\u001b[0m     rankby_abs\u001b[39m=\u001b[39;49mrankby_abs,\n\u001b[1;32m     42\u001b[0m     n_genes\u001b[39m=\u001b[39;49mn_genes,\n\u001b[1;32m     43\u001b[0m     use_raw\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     46\u001b[0m \u001b[39m#add entries to dictionary of gene sets\u001b[39;00m\n\u001b[1;32m     47\u001b[0m de_genes \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(adata_cov\u001b[39m.\u001b[39muns[\u001b[39m'\u001b[39m\u001b[39mrank_genes_groups\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/.apps/conda/envs/rtd/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py:576\u001b[0m, in \u001b[0;36mrank_genes_groups\u001b[0;34m(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[39mif\u001b[39;00m reference \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrest\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m reference \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m adata\u001b[39m.\u001b[39mobs[groupby]\u001b[39m.\u001b[39mcat\u001b[39m.\u001b[39mcategories:\n\u001b[1;32m    575\u001b[0m     cats \u001b[39m=\u001b[39m adata\u001b[39m.\u001b[39mobs[groupby]\u001b[39m.\u001b[39mcat\u001b[39m.\u001b[39mcategories\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m--> 576\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    577\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mreference = \u001b[39m\u001b[39m{\u001b[39;00mreference\u001b[39m}\u001b[39;00m\u001b[39m needs to be one of groupby = \u001b[39m\u001b[39m{\u001b[39;00mcats\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    578\u001b[0m     )\n\u001b[1;32m    580\u001b[0m \u001b[39mif\u001b[39;00m key_added \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    581\u001b[0m     key_added \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrank_genes_groups\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: reference = K562_ctrl_1 needs to be one of groupby = ['K562_p_INTERGENIC216151_1', 'K562_p_INTERGENIC393453_1', 'K562_p_INTERGENIC1144056_1', 'K562_p_INTERGENIC1216445_1', 'K562_p_sgCREB1_2_1', 'K562_p_sgCREB1_4_1', 'K562_p_sgCREB1_5_1', 'K562_p_sgE2F4_6_1', 'K562_p_sgE2F4_7_1', 'K562_p_sgEGR1_2_1', 'K562_p_sgEGR1_4_1', 'K562_p_sgELF1_1_1', 'K562_p_sgELF1_2_1', 'K562_p_sgELF1_4_1', 'K562_p_sgELF1_5_1', 'K562_p_sgELK1_1_1', 'K562_p_sgELK1_6_1', 'K562_p_sgELK1_7_1', 'K562_p_sgETS1_3_1', 'K562_p_sgETS1_5_1', 'K562_p_sgGABPA_1_1', 'K562_p_sgGABPA_9_1', 'K562_p_sgIRF1_2_1', 'K562_p_sgIRF1_3_1', 'K562_p_sgNR2C2_2_1', 'K562_p_sgNR2C2_3_1', 'K562_p_sgNR2C2_5_1', 'K562_p_sgYY1_3_1', 'K562_p_sgYY1_10_1']."
     ]
    }
   ],
   "source": [
    "pert_data = PertData(\"./data\")\n",
    "pert_data.new_data_process(dataset_name = \"dixit\", adata = no_na_adata)\n",
    "pert_data.load(data_name='./data/dixit') # load the processed data, path is saved folder + dataset name\n",
    "pert_data.prepare_split(split=split, seed=1)\n",
    "pert_data.get_dataloader(batch_size=batch_size, test_batch_size=eval_batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/bench-user/perturbation_model/tutorials/Perturbation_Prediction.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://code-server-protective-parrot-ajf.us-west-2.aws.bench.deeporigin.io/home/bench-user/perturbation_model/tutorials/Perturbation_Prediction.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m save_dir \u001b[39m=\u001b[39m Path(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./save/dev_perturb_\u001b[39m\u001b[39m{\u001b[39;00mdata_name\u001b[39m}\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m{\u001b[39;00mtime\u001b[39m.\u001b[39mstrftime(\u001b[39m'\u001b[39m\u001b[39m%\u001b[39m\u001b[39mb\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mH-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mM\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://code-server-protective-parrot-ajf.us-west-2.aws.bench.deeporigin.io/home/bench-user/perturbation_model/tutorials/Perturbation_Prediction.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m save_dir\u001b[39m.\u001b[39mmkdir(parents\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://code-server-protective-parrot-ajf.us-west-2.aws.bench.deeporigin.io/home/bench-user/perturbation_model/tutorials/Perturbation_Prediction.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msaving to \u001b[39m\u001b[39m{\u001b[39;00msave_dir\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_name' is not defined"
     ]
    }
   ],
   "source": [
    "save_dir = Path(f\"./save/dev_perturb_{data_name}-{time.strftime('%b%d-%H-%M')}/\")\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"saving to {save_dir}\")\n",
    "\n",
    "logger = scg.logger\n",
    "scg.utils.add_file_handler(logger, save_dir / \"run.log\")\n",
    "# log running date and current git commit\n",
    "logger.info(f\"Running on {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - match 4399/5060 genes in vocabulary of size 60697.\n",
      "scGPT - INFO - Resume model from ../save/scGPT_human/best_model.pt, the model args will override the config ../save/scGPT_human/args.json.\n"
     ]
    }
   ],
   "source": [
    "if load_model is not None:\n",
    "    model_dir = Path(load_model)\n",
    "    assert model_dir.exists(), \"Model directory does not exist\"\n",
    "    \n",
    "    model_config_file = model_dir / \"args.json\"\n",
    "    model_file = model_dir / \"best_model.pt\"\n",
    "    vocab_file = model_dir / \"vocab.json\"\n",
    "\n",
    "    vocab = GeneVocab.from_file(vocab_file)\n",
    "    for s in special_tokens:\n",
    "        if s not in vocab:\n",
    "            vocab.append_token(s)\n",
    "\n",
    "    pert_data.adata.var[\"id_in_vocab\"] = [\n",
    "        1 if gene in vocab else -1 for gene in pert_data.adata.var[\"gene_name\"]\n",
    "    ]\n",
    "    gene_ids_in_vocab = np.array(pert_data.adata.var[\"id_in_vocab\"])\n",
    "    logger.info(\n",
    "        f\"match {np.sum(gene_ids_in_vocab >= 0)}/{len(gene_ids_in_vocab)} genes \"\n",
    "        f\"in vocabulary of size {len(vocab)}.\"\n",
    "    )\n",
    "    genes = pert_data.adata.var[\"gene_name\"].tolist()\n",
    "\n",
    "    # model\n",
    "    with open(model_config_file, \"r\") as f:\n",
    "        model_configs = json.load(f)\n",
    "    logger.info(\n",
    "        f\"Resume model from {model_file}, the model args will override the \"\n",
    "        f\"config {model_config_file}.\"\n",
    "    )\n",
    "    embsize = model_configs[\"embsize\"]\n",
    "    nhead = model_configs[\"nheads\"]\n",
    "    d_hid = model_configs[\"d_hid\"]\n",
    "    nlayers = model_configs[\"nlayers\"]\n",
    "    n_layers_cls = model_configs[\"n_layers_cls\"]\n",
    "else:\n",
    "    genes = pert_data.adata.var[\"gene_name\"].tolist()\n",
    "    vocab = Vocab(\n",
    "        VocabPybind(genes + special_tokens, None)\n",
    "    )  # bidirectional lookup [gene <-> int]\n",
    "vocab.set_default_index(vocab[\"<pad>\"])\n",
    "gene_ids = np.array(\n",
    "    [vocab[gene] if gene in vocab else vocab[\"<pad>\"] for gene in genes], dtype=int\n",
    ")\n",
    "n_genes = len(genes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Create and train scGpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using simple batchnorm instead of domain specific batchnorm\n",
      "scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])\n",
      "scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])\n",
      "scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TransformerGenerator(\n",
       "  (encoder): GeneEncoder(\n",
       "    (embedding): Embedding(60697, 512, padding_idx=60694)\n",
       "    (enc_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (value_encoder): ContinuousValueEncoder(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (linear1): Linear(in_features=1, out_features=512, bias=True)\n",
       "    (activation): ReLU()\n",
       "    (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (pert_encoder): Embedding(3, 512, padding_idx=2)\n",
       "  (bn): BatchNorm1d(512, eps=6.1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): FlashTransformerEncoderLayer(\n",
       "        (self_attn): FlashMHA(\n",
       "          (Wqkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (inner_attn): FlashAttention()\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (1): FlashTransformerEncoderLayer(\n",
       "        (self_attn): FlashMHA(\n",
       "          (Wqkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (inner_attn): FlashAttention()\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (2): FlashTransformerEncoderLayer(\n",
       "        (self_attn): FlashMHA(\n",
       "          (Wqkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (inner_attn): FlashAttention()\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (3): FlashTransformerEncoderLayer(\n",
       "        (self_attn): FlashMHA(\n",
       "          (Wqkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (inner_attn): FlashAttention()\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (4): FlashTransformerEncoderLayer(\n",
       "        (self_attn): FlashMHA(\n",
       "          (Wqkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (inner_attn): FlashAttention()\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (5): FlashTransformerEncoderLayer(\n",
       "        (self_attn): FlashMHA(\n",
       "          (Wqkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (inner_attn): FlashAttention()\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (6): FlashTransformerEncoderLayer(\n",
       "        (self_attn): FlashMHA(\n",
       "          (Wqkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (inner_attn): FlashAttention()\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (7): FlashTransformerEncoderLayer(\n",
       "        (self_attn): FlashMHA(\n",
       "          (Wqkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (inner_attn): FlashAttention()\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (8): FlashTransformerEncoderLayer(\n",
       "        (self_attn): FlashMHA(\n",
       "          (Wqkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (inner_attn): FlashAttention()\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (9): FlashTransformerEncoderLayer(\n",
       "        (self_attn): FlashMHA(\n",
       "          (Wqkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (inner_attn): FlashAttention()\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (10): FlashTransformerEncoderLayer(\n",
       "        (self_attn): FlashMHA(\n",
       "          (Wqkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (inner_attn): FlashAttention()\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (11): FlashTransformerEncoderLayer(\n",
       "        (self_attn): FlashMHA(\n",
       "          (Wqkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (inner_attn): FlashAttention()\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): ExprDecoder(\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=512, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (cls_decoder): ClsDecoder(\n",
       "    (_decoder): ModuleList(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (out_layer): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       "  (sim): Similarity(\n",
       "    (cos): CosineSimilarity()\n",
       "  )\n",
       "  (creterion_cce): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ntokens = len(vocab)  # size of vocabulary\n",
    "model = TransformerGenerator(\n",
    "    ntokens,\n",
    "    embsize,\n",
    "    nhead,\n",
    "    d_hid,\n",
    "    nlayers,\n",
    "    nlayers_cls=n_layers_cls,\n",
    "    n_cls=1,\n",
    "    vocab=vocab,\n",
    "    dropout=dropout,\n",
    "    pad_token=pad_token,\n",
    "    pad_value=pad_value,\n",
    "    pert_pad_id=pert_pad_id,\n",
    "    do_mvc=MVC,\n",
    "    cell_emb_style=cell_emb_style,\n",
    "    mvc_decoder_style=mvc_decoder_style,\n",
    "    use_fast_transformer=use_fast_transformer,\n",
    ")\n",
    "if load_param_prefixs is not None and load_model is not None:\n",
    "    # only load params that start with the prefix\n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_dict = torch.load(model_file)\n",
    "    pretrained_dict = {\n",
    "        k: v\n",
    "        for k, v in pretrained_dict.items()\n",
    "        if any([k.startswith(prefix) for prefix in load_param_prefixs])\n",
    "    }\n",
    "    for k, v in pretrained_dict.items():\n",
    "        logger.info(f\"Loading params {k} with shape {v.shape}\")\n",
    "    model_dict.update(pretrained_dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "elif load_model is not None:\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "        logger.info(f\"Loading all model params from {model_file}\")\n",
    "    except:\n",
    "        # only load params that are in the model and match the size\n",
    "        model_dict = model.state_dict()\n",
    "        pretrained_dict = torch.load(model_file)\n",
    "        pretrained_dict = {\n",
    "            k: v\n",
    "            for k, v in pretrained_dict.items()\n",
    "            if k in model_dict and v.shape == model_dict[k].shape\n",
    "        }\n",
    "        for k, v in pretrained_dict.items():\n",
    "            logger.info(f\"Loading params {k} with shape {v.shape}\")\n",
    "        model_dict.update(pretrained_dict)\n",
    "        model.load_state_dict(model_dict)\n",
    "model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = masked_mse_loss\n",
    "criterion_cls = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, schedule_interval, gamma=0.9)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
    "\n",
    "\n",
    "def train(model: nn.Module, train_loader: torch.utils.data.DataLoader) -> None:\n",
    "    \"\"\"\n",
    "    Train the model for one epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss, total_mse = 0.0, 0.0\n",
    "    start_time = time.time()\n",
    "\n",
    "    num_batches = len(train_loader)\n",
    "    for batch, batch_data in enumerate(train_loader):\n",
    "        batch_size = len(batch_data.y)\n",
    "        batch_data.to(device)\n",
    "        x: torch.Tensor = batch_data.x  # (batch_size * n_genes, 2)\n",
    "        ori_gene_values = x[:, 0].view(batch_size, n_genes)\n",
    "        pert_flags = x[:, 1].long().view(batch_size, n_genes)\n",
    "        target_gene_values = batch_data.y  # (batch_size, n_genes)\n",
    "\n",
    "        if include_zero_gene in [\"all\", \"batch-wise\"]:\n",
    "            if include_zero_gene == \"all\":\n",
    "                input_gene_ids = torch.arange(n_genes, device=device, dtype=torch.long)\n",
    "            else:\n",
    "                input_gene_ids = (\n",
    "                    ori_gene_values.nonzero()[:, 1].flatten().unique().sort()[0]\n",
    "                )\n",
    "            # sample input_gene_id\n",
    "            if len(input_gene_ids) > max_seq_len:\n",
    "                input_gene_ids = torch.randperm(len(input_gene_ids), device=device)[\n",
    "                    :max_seq_len\n",
    "                ]\n",
    "            input_values = ori_gene_values[:, input_gene_ids]\n",
    "            input_pert_flags = pert_flags[:, input_gene_ids]\n",
    "            target_values = target_gene_values[:, input_gene_ids]\n",
    "\n",
    "            mapped_input_gene_ids = map_raw_id_to_vocab_id(input_gene_ids, gene_ids)\n",
    "            mapped_input_gene_ids = mapped_input_gene_ids.repeat(batch_size, 1)\n",
    "\n",
    "            # src_key_padding_mask = mapped_input_gene_ids.eq(vocab[pad_token])\n",
    "            src_key_padding_mask = torch.zeros_like(\n",
    "                input_values, dtype=torch.bool, device=device\n",
    "            )\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=amp):\n",
    "            output_dict = model(\n",
    "                mapped_input_gene_ids,\n",
    "                input_values,\n",
    "                input_pert_flags,\n",
    "                src_key_padding_mask=src_key_padding_mask,\n",
    "                CLS=CLS,\n",
    "                CCE=CCE,\n",
    "                MVC=MVC,\n",
    "                ECS=ECS,\n",
    "            )\n",
    "            output_values = output_dict[\"mlm_output\"]\n",
    "\n",
    "            masked_positions = torch.ones_like(\n",
    "                input_values, dtype=torch.bool\n",
    "            )  # Use all\n",
    "            loss = loss_mse = criterion(output_values, target_values, masked_positions)\n",
    "\n",
    "        model.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        with warnings.catch_warnings(record=True) as w:\n",
    "            warnings.filterwarnings(\"always\")\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                model.parameters(),\n",
    "                1.0,\n",
    "                error_if_nonfinite=False if scaler.is_enabled() else True,\n",
    "            )\n",
    "            if len(w) > 0:\n",
    "                logger.warning(\n",
    "                    f\"Found infinite gradient. This may be caused by the gradient \"\n",
    "                    f\"scaler. The current scale is {scaler.get_scale()}. This warning \"\n",
    "                    \"can be ignored if no longer occurs after autoscaling of the scaler.\"\n",
    "                )\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # torch.cuda.empty_cache()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_mse += loss_mse.item()\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            cur_mse = total_mse / log_interval\n",
    "            # ppl = math.exp(cur_loss)\n",
    "            logger.info(\n",
    "                f\"| epoch {epoch:3d} | {batch:3d}/{num_batches:3d} batches | \"\n",
    "                f\"lr {lr:05.4f} | ms/batch {ms_per_batch:5.2f} | \"\n",
    "                f\"loss {cur_loss:5.2f} | mse {cur_mse:5.2f} |\"\n",
    "            )\n",
    "            total_loss = 0\n",
    "            total_mse = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "\n",
    "def evaluate(model: nn.Module, val_loader: torch.utils.data.DataLoader) -> float:\n",
    "    \"\"\"\n",
    "    Evaluate the model on the evaluation data.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_error = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, batch_data in enumerate(val_loader):\n",
    "            batch_size = len(batch_data.y)\n",
    "            batch_data.to(device)\n",
    "            x: torch.Tensor = batch_data.x  # (batch_size * n_genes, 2)\n",
    "            ori_gene_values = x[:, 0].view(batch_size, n_genes)\n",
    "            pert_flags = x[:, 1].long().view(batch_size, n_genes)\n",
    "            target_gene_values = batch_data.y  # (batch_size, n_genes)\n",
    "\n",
    "            if include_zero_gene in [\"all\", \"batch-wise\"]:\n",
    "                if include_zero_gene == \"all\":\n",
    "                    input_gene_ids = torch.arange(n_genes, device=device)\n",
    "                else:  # when batch-wise\n",
    "                    input_gene_ids = (\n",
    "                        ori_gene_values.nonzero()[:, 1].flatten().unique().sort()[0]\n",
    "                    )\n",
    "\n",
    "                # sample input_gene_id\n",
    "                if len(input_gene_ids) > max_seq_len:\n",
    "                    input_gene_ids = torch.randperm(len(input_gene_ids), device=device)[\n",
    "                        :max_seq_len\n",
    "                    ]\n",
    "                input_values = ori_gene_values[:, input_gene_ids]\n",
    "                input_pert_flags = pert_flags[:, input_gene_ids]\n",
    "                target_values = target_gene_values[:, input_gene_ids]\n",
    "\n",
    "                mapped_input_gene_ids = map_raw_id_to_vocab_id(input_gene_ids, gene_ids)\n",
    "                mapped_input_gene_ids = mapped_input_gene_ids.repeat(batch_size, 1)\n",
    "\n",
    "                # src_key_padding_mask = mapped_input_gene_ids.eq(vocab[pad_token])\n",
    "                src_key_padding_mask = torch.zeros_like(\n",
    "                    input_values, dtype=torch.bool, device=input_values.device\n",
    "                )\n",
    "            with torch.cuda.amp.autocast(enabled=amp):\n",
    "                output_dict = model(\n",
    "                    mapped_input_gene_ids,\n",
    "                    input_values,\n",
    "                    input_pert_flags,\n",
    "                    src_key_padding_mask=src_key_padding_mask,\n",
    "                    CLS=CLS,\n",
    "                    CCE=CCE,\n",
    "                    MVC=MVC,\n",
    "                    ECS=ECS,\n",
    "                    do_sample=True,\n",
    "                )\n",
    "                output_values = output_dict[\"mlm_output\"]\n",
    "\n",
    "                masked_positions = torch.ones_like(\n",
    "                    input_values, dtype=torch.bool, device=input_values.device\n",
    "                )\n",
    "                loss = criterion(output_values, target_values, masked_positions)\n",
    "            total_loss += loss.item()\n",
    "            total_error += masked_relative_error(\n",
    "                output_values, target_values, masked_positions\n",
    "            ).item()\n",
    "    return total_loss / len(val_loader), total_error / len(val_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - | epoch   1 | 100/849 batches | lr 0.0001 | ms/batch 349.85 | loss  0.13 | mse  0.13 |\n",
      "scGPT - INFO - | epoch   1 | 200/849 batches | lr 0.0001 | ms/batch 347.33 | loss  0.09 | mse  0.09 |\n",
      "scGPT - INFO - | epoch   1 | 300/849 batches | lr 0.0001 | ms/batch 347.91 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   1 | 400/849 batches | lr 0.0001 | ms/batch 347.70 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   1 | 500/849 batches | lr 0.0001 | ms/batch 347.07 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   1 | 600/849 batches | lr 0.0001 | ms/batch 347.23 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   1 | 700/849 batches | lr 0.0001 | ms/batch 347.21 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   1 | 800/849 batches | lr 0.0001 | ms/batch 347.31 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch   1 | time: 299.08s | valid loss/mse 0.1373 |\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - Best model with score 0.1373\n",
      "scGPT - INFO - | epoch   2 | 100/849 batches | lr 0.0001 | ms/batch 347.63 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   2 | 200/849 batches | lr 0.0001 | ms/batch 347.29 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   2 | 300/849 batches | lr 0.0001 | ms/batch 347.17 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   2 | 400/849 batches | lr 0.0001 | ms/batch 346.59 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   2 | 500/849 batches | lr 0.0001 | ms/batch 347.25 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   2 | 600/849 batches | lr 0.0001 | ms/batch 347.06 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   2 | 700/849 batches | lr 0.0001 | ms/batch 347.62 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   2 | 800/849 batches | lr 0.0001 | ms/batch 347.03 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch   2 | time: 298.68s | valid loss/mse 0.1375 |\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | epoch   3 | 100/849 batches | lr 0.0001 | ms/batch 350.56 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   3 | 200/849 batches | lr 0.0001 | ms/batch 346.59 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   3 | 300/849 batches | lr 0.0001 | ms/batch 346.73 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   3 | 400/849 batches | lr 0.0001 | ms/batch 347.00 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   3 | 500/849 batches | lr 0.0001 | ms/batch 347.14 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   3 | 600/849 batches | lr 0.0001 | ms/batch 347.38 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   3 | 700/849 batches | lr 0.0001 | ms/batch 347.23 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   3 | 800/849 batches | lr 0.0001 | ms/batch 347.14 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch   3 | time: 298.94s | valid loss/mse 0.1359 |\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - Best model with score 0.1359\n",
      "scGPT - INFO - | epoch   4 | 100/849 batches | lr 0.0001 | ms/batch 350.52 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   4 | 200/849 batches | lr 0.0001 | ms/batch 346.88 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   4 | 300/849 batches | lr 0.0001 | ms/batch 347.00 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   4 | 400/849 batches | lr 0.0001 | ms/batch 347.52 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   4 | 500/849 batches | lr 0.0001 | ms/batch 346.55 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   4 | 600/849 batches | lr 0.0001 | ms/batch 347.25 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   4 | 700/849 batches | lr 0.0001 | ms/batch 347.23 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   4 | 800/849 batches | lr 0.0001 | ms/batch 346.89 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch   4 | time: 298.89s | valid loss/mse 0.1354 |\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - Best model with score 0.1354\n",
      "scGPT - INFO - | epoch   5 | 100/849 batches | lr 0.0001 | ms/batch 350.21 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   5 | 200/849 batches | lr 0.0001 | ms/batch 347.01 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   5 | 300/849 batches | lr 0.0001 | ms/batch 347.14 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   5 | 400/849 batches | lr 0.0001 | ms/batch 347.01 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   5 | 500/849 batches | lr 0.0001 | ms/batch 346.98 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   5 | 600/849 batches | lr 0.0001 | ms/batch 347.23 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   5 | 700/849 batches | lr 0.0001 | ms/batch 347.07 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   5 | 800/849 batches | lr 0.0001 | ms/batch 347.25 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch   5 | time: 298.87s | valid loss/mse 0.1364 |\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | epoch   6 | 100/849 batches | lr 0.0001 | ms/batch 349.59 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   6 | 200/849 batches | lr 0.0001 | ms/batch 347.04 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   6 | 300/849 batches | lr 0.0001 | ms/batch 347.12 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   6 | 400/849 batches | lr 0.0001 | ms/batch 346.49 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   6 | 500/849 batches | lr 0.0001 | ms/batch 346.99 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   6 | 600/849 batches | lr 0.0001 | ms/batch 347.02 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   6 | 700/849 batches | lr 0.0001 | ms/batch 346.86 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   6 | 800/849 batches | lr 0.0001 | ms/batch 347.34 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch   6 | time: 298.77s | valid loss/mse 0.1352 |\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - Best model with score 0.1352\n",
      "scGPT - INFO - | epoch   7 | 100/849 batches | lr 0.0001 | ms/batch 349.76 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   7 | 200/849 batches | lr 0.0001 | ms/batch 346.70 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   7 | 300/849 batches | lr 0.0001 | ms/batch 346.65 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   7 | 400/849 batches | lr 0.0001 | ms/batch 347.09 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   7 | 500/849 batches | lr 0.0001 | ms/batch 346.92 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   7 | 600/849 batches | lr 0.0001 | ms/batch 346.92 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   7 | 700/849 batches | lr 0.0001 | ms/batch 347.06 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   7 | 800/849 batches | lr 0.0001 | ms/batch 347.31 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch   7 | time: 298.74s | valid loss/mse 0.1368 |\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | epoch   8 | 100/849 batches | lr 0.0000 | ms/batch 349.62 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   8 | 200/849 batches | lr 0.0000 | ms/batch 346.76 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   8 | 300/849 batches | lr 0.0000 | ms/batch 346.87 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   8 | 400/849 batches | lr 0.0000 | ms/batch 347.17 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   8 | 500/849 batches | lr 0.0000 | ms/batch 347.15 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   8 | 600/849 batches | lr 0.0000 | ms/batch 347.34 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   8 | 700/849 batches | lr 0.0000 | ms/batch 347.14 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   8 | 800/849 batches | lr 0.0000 | ms/batch 346.92 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch   8 | time: 298.82s | valid loss/mse 0.1352 |\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - Best model with score 0.1352\n",
      "scGPT - INFO - | epoch   9 | 100/849 batches | lr 0.0000 | ms/batch 349.88 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   9 | 200/849 batches | lr 0.0000 | ms/batch 346.84 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   9 | 300/849 batches | lr 0.0000 | ms/batch 346.99 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   9 | 400/849 batches | lr 0.0000 | ms/batch 346.72 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   9 | 500/849 batches | lr 0.0000 | ms/batch 347.14 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   9 | 600/849 batches | lr 0.0000 | ms/batch 347.16 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   9 | 700/849 batches | lr 0.0000 | ms/batch 347.26 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch   9 | 800/849 batches | lr 0.0000 | ms/batch 346.73 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch   9 | time: 298.79s | valid loss/mse 0.1356 |\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | epoch  10 | 100/849 batches | lr 0.0000 | ms/batch 349.94 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  10 | 200/849 batches | lr 0.0000 | ms/batch 347.09 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  10 | 300/849 batches | lr 0.0000 | ms/batch 346.88 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  10 | 400/849 batches | lr 0.0000 | ms/batch 347.00 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  10 | 500/849 batches | lr 0.0000 | ms/batch 347.28 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  10 | 600/849 batches | lr 0.0000 | ms/batch 347.24 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  10 | 700/849 batches | lr 0.0000 | ms/batch 347.30 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  10 | 800/849 batches | lr 0.0000 | ms/batch 347.63 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch  10 | time: 298.95s | valid loss/mse 0.1333 |\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - Best model with score 0.1333\n",
      "scGPT - INFO - | epoch  11 | 100/849 batches | lr 0.0000 | ms/batch 350.28 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  11 | 200/849 batches | lr 0.0000 | ms/batch 347.03 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  11 | 300/849 batches | lr 0.0000 | ms/batch 346.87 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  11 | 400/849 batches | lr 0.0000 | ms/batch 346.88 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  11 | 500/849 batches | lr 0.0000 | ms/batch 346.83 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  11 | 600/849 batches | lr 0.0000 | ms/batch 347.43 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  11 | 700/849 batches | lr 0.0000 | ms/batch 346.82 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  11 | 800/849 batches | lr 0.0000 | ms/batch 346.90 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch  11 | time: 298.78s | valid loss/mse 0.1357 |\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | epoch  12 | 100/849 batches | lr 0.0000 | ms/batch 349.86 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  12 | 200/849 batches | lr 0.0000 | ms/batch 347.24 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  12 | 300/849 batches | lr 0.0000 | ms/batch 347.01 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  12 | 400/849 batches | lr 0.0000 | ms/batch 347.18 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  12 | 500/849 batches | lr 0.0000 | ms/batch 347.16 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  12 | 600/849 batches | lr 0.0000 | ms/batch 346.99 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  12 | 700/849 batches | lr 0.0000 | ms/batch 347.13 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  12 | 800/849 batches | lr 0.0000 | ms/batch 347.15 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch  12 | time: 298.85s | valid loss/mse 0.1321 |\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - Best model with score 0.1321\n",
      "scGPT - INFO - | epoch  13 | 100/849 batches | lr 0.0000 | ms/batch 349.99 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  13 | 200/849 batches | lr 0.0000 | ms/batch 347.36 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  13 | 300/849 batches | lr 0.0000 | ms/batch 347.23 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  13 | 400/849 batches | lr 0.0000 | ms/batch 347.07 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  13 | 500/849 batches | lr 0.0000 | ms/batch 346.83 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  13 | 600/849 batches | lr 0.0000 | ms/batch 347.54 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  13 | 700/849 batches | lr 0.0000 | ms/batch 347.16 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  13 | 800/849 batches | lr 0.0000 | ms/batch 346.83 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch  13 | time: 298.94s | valid loss/mse 0.1378 |\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | epoch  14 | 100/849 batches | lr 0.0000 | ms/batch 350.03 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  14 | 200/849 batches | lr 0.0000 | ms/batch 347.42 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  14 | 300/849 batches | lr 0.0000 | ms/batch 347.32 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  14 | 400/849 batches | lr 0.0000 | ms/batch 347.37 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  14 | 500/849 batches | lr 0.0000 | ms/batch 347.06 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  14 | 600/849 batches | lr 0.0000 | ms/batch 347.28 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  14 | 700/849 batches | lr 0.0000 | ms/batch 346.85 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  14 | 800/849 batches | lr 0.0000 | ms/batch 346.77 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch  14 | time: 298.97s | valid loss/mse 0.1339 |\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | epoch  15 | 100/849 batches | lr 0.0000 | ms/batch 350.67 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  15 | 200/849 batches | lr 0.0000 | ms/batch 346.56 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  15 | 300/849 batches | lr 0.0000 | ms/batch 347.44 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  15 | 400/849 batches | lr 0.0000 | ms/batch 346.89 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  15 | 500/849 batches | lr 0.0000 | ms/batch 347.05 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  15 | 600/849 batches | lr 0.0000 | ms/batch 346.89 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  15 | 700/849 batches | lr 0.0000 | ms/batch 347.35 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - | epoch  15 | 800/849 batches | lr 0.0000 | ms/batch 347.19 | loss  0.08 | mse  0.08 |\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch  15 | time: 298.90s | valid loss/mse 0.1361 |\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "best_model = None\n",
    "patience = 0\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train_loader = pert_data.dataloader[\"train_loader\"]\n",
    "    valid_loader = pert_data.dataloader[\"val_loader\"]\n",
    "\n",
    "    train(\n",
    "        model,\n",
    "        train_loader,\n",
    "    )\n",
    "    val_loss, val_mre = evaluate(\n",
    "        model,\n",
    "        valid_loader,\n",
    "    )\n",
    "    elapsed = time.time() - epoch_start_time\n",
    "    logger.info(\"-\" * 89)\n",
    "    logger.info(\n",
    "        f\"| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | \"\n",
    "        f\"valid loss/mse {val_loss:5.4f} |\"\n",
    "    )\n",
    "    logger.info(\"-\" * 89)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = copy.deepcopy(model)\n",
    "        logger.info(f\"Best model with score {best_val_loss:5.4f}\")\n",
    "        patience = 0\n",
    "    else:\n",
    "        patience += 1\n",
    "        if patience >= early_stop:\n",
    "            logger.info(f\"Early stop at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "    torch.save(\n",
    "        model.state_dict(),\n",
    "        save_dir / f\"model_{epoch}.pt\",\n",
    "    )\n",
    "\n",
    "    scheduler.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model.state_dict(), save_dir / \"best_model.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(\n",
    "    model: TransformerGenerator, pert_list: List[str], pool_size: Optional[int] = None\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Predict the gene expression values for the given perturbations.\n",
    "\n",
    "    Args:\n",
    "        model (:class:`torch.nn.Module`): The model to use for prediction.\n",
    "        pert_list (:obj:`List[str]`): The list of perturbations to predict.\n",
    "        pool_size (:obj:`int`, optional): For each perturbation, use this number\n",
    "            of cells in the control and predict their perturbation results. Report\n",
    "            the stats of these predictions. If `None`, use all control cells.\n",
    "    \"\"\"\n",
    "    adata = pert_data.adata\n",
    "    ctrl_adata = adata[adata.obs[\"condition\"] == \"ctrl\"]\n",
    "    if pool_size is None:\n",
    "        pool_size = len(ctrl_adata.obs)\n",
    "    gene_list = pert_data.gene_names.values.tolist()\n",
    "    for pert in pert_list:\n",
    "        for i in pert:\n",
    "            if i not in gene_list:\n",
    "                raise ValueError(\n",
    "                    \"The gene is not in the perturbation graph. Please select from GEARS.gene_list!\"\n",
    "                )\n",
    "\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    with torch.no_grad():\n",
    "        results_pred = {}\n",
    "        for pert in pert_list:\n",
    "            cell_graphs = create_cell_graph_dataset_for_prediction(\n",
    "                pert, ctrl_adata, gene_list, device, num_samples=pool_size\n",
    "            )\n",
    "            loader = DataLoader(cell_graphs, batch_size=eval_batch_size, shuffle=False)\n",
    "            preds = []\n",
    "            for batch_data in loader:\n",
    "                pred_gene_values = model.pred_perturb(\n",
    "                    batch_data, include_zero_gene, gene_ids=gene_ids, amp=amp\n",
    "                )\n",
    "                preds.append(pred_gene_values)\n",
    "            preds = torch.cat(preds, dim=0)\n",
    "            results_pred[\"_\".join(pert)] = np.mean(preds.detach().cpu().numpy(), axis=0)\n",
    "\n",
    "    return results_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_perturbation(\n",
    "    model: nn.Module, query: str, save_file: str = None, pool_size: int = None\n",
    "):\n",
    "    import seaborn as sns\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    sns.set_theme(style=\"ticks\", rc={\"axes.facecolor\": (0, 0, 0, 0)}, font_scale=1.5)\n",
    "\n",
    "    adata = pert_data.adata\n",
    "    gene2idx = pert_data.node_map\n",
    "    cond2name = dict(adata.obs[[\"condition\", \"condition_name\"]].values)\n",
    "    gene_raw2id = dict(zip(adata.var.index.values, adata.var.gene_name.values))\n",
    "\n",
    "    de_idx = [\n",
    "        gene2idx[gene_raw2id[i]]\n",
    "        for i in adata.uns[\"top_non_dropout_de_20\"][cond2name[query]]\n",
    "    ]\n",
    "    genes = [\n",
    "        gene_raw2id[i] for i in adata.uns[\"top_non_dropout_de_20\"][cond2name[query]]\n",
    "    ]\n",
    "    truth = adata[adata.obs.condition == query].X.toarray()[:, de_idx]\n",
    "    if query.split(\"+\")[1] == \"ctrl\":\n",
    "        pred = predict(model, [[query.split(\"+\")[0]]], pool_size=pool_size)\n",
    "        pred = pred[query.split(\"+\")[0]][de_idx]\n",
    "    else:\n",
    "        pred = predict(model, [query.split(\"+\")], pool_size=pool_size)\n",
    "        pred = pred[\"_\".join(query.split(\"+\"))][de_idx]\n",
    "    ctrl_means = adata[adata.obs[\"condition\"] == \"ctrl\"].to_df().mean()[de_idx].values\n",
    "\n",
    "    pred = pred - ctrl_means\n",
    "    truth = truth - ctrl_means\n",
    "\n",
    "    plt.figure(figsize=[16.5, 4.5])\n",
    "    plt.title(query)\n",
    "    plt.boxplot(truth, showfliers=False, medianprops=dict(linewidth=0))\n",
    "\n",
    "    for i in range(pred.shape[0]):\n",
    "        _ = plt.scatter(i + 1, pred[i], color=\"red\")\n",
    "\n",
    "    plt.axhline(0, linestyle=\"dashed\", color=\"green\")\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_ticklabels(genes, rotation=90)\n",
    "\n",
    "    plt.ylabel(\"Change in Gene Expression over Control\", labelpad=10)\n",
    "    plt.tick_params(axis=\"x\", which=\"major\", pad=5)\n",
    "    plt.tick_params(axis=\"y\", which=\"major\", pad=5)\n",
    "    sns.despine()\n",
    "\n",
    "    if save_file:\n",
    "        plt.savefig(save_file, bbox_inches=\"tight\", transparent=False)\n",
    "    # plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1188x324 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict(best_model, [[\"FEV\"], [\"FEV\", \"SAMD11\"]])\n",
    "for p in perts_to_plot:\n",
    "    plot_perturbation(best_model, p, pool_size=300, save_file=f\"{save_dir}/{p}.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_perturb(\n",
    "    loader: DataLoader, model: TransformerGenerator, device: torch.device\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Run model in inference mode using a given data loader\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    pert_cat = []\n",
    "    pred = []\n",
    "    truth = []\n",
    "    pred_de = []\n",
    "    truth_de = []\n",
    "    results = {}\n",
    "    logvar = []\n",
    "\n",
    "    for itr, batch in enumerate(loader):\n",
    "        batch.to(device)\n",
    "        pert_cat.extend(batch.pert)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            p = model.pred_perturb(batch, include_zero_gene, gene_ids=gene_ids)\n",
    "            t = batch.y\n",
    "            pred.extend(p.cpu())\n",
    "            truth.extend(t.cpu())\n",
    "\n",
    "            # Differentially expressed genes\n",
    "            for itr, de_idx in enumerate(batch.de_idx):\n",
    "                pred_de.append(p[itr, de_idx])\n",
    "                truth_de.append(t[itr, de_idx])\n",
    "\n",
    "    # all genes\n",
    "    results[\"pert_cat\"] = np.array(pert_cat)\n",
    "    pred = torch.stack(pred)\n",
    "    truth = torch.stack(truth)\n",
    "    results[\"pred\"] = pred.detach().cpu().numpy().astype(np.float)\n",
    "    results[\"truth\"] = truth.detach().cpu().numpy().astype(np.float)\n",
    "\n",
    "    pred_de = torch.stack(pred_de)\n",
    "    truth_de = torch.stack(truth_de)\n",
    "    results[\"pred_de\"] = pred_de.detach().cpu().numpy().astype(np.float)\n",
    "    results[\"truth_de\"] = truth_de.detach().cpu().numpy().astype(np.float)\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': 0.00633879785470548, 'mse_de': 0.12994101050959672, 'pearson': 0.9901751059128802, 'pearson_de': 0.9778788141012438}\n",
      "scGPT - INFO - test_combo_seen0_pearson_delta: nan\n",
      "scGPT - INFO - test_combo_seen0_pearson_delta_de: nan\n",
      "scGPT - INFO - test_combo_seen0_pearson_delta_top20_de_non_dropout: nan\n",
      "scGPT - INFO - test_combo_seen0_pearson_top20_de_non_dropout: nan\n",
      "scGPT - INFO - test_combo_seen1_pearson_delta: nan\n",
      "scGPT - INFO - test_combo_seen1_pearson_delta_de: nan\n",
      "scGPT - INFO - test_combo_seen1_pearson_delta_top20_de_non_dropout: nan\n",
      "scGPT - INFO - test_combo_seen1_pearson_top20_de_non_dropout: nan\n",
      "scGPT - INFO - test_combo_seen2_pearson_delta: nan\n",
      "scGPT - INFO - test_combo_seen2_pearson_delta_de: nan\n",
      "scGPT - INFO - test_combo_seen2_pearson_delta_top20_de_non_dropout: nan\n",
      "scGPT - INFO - test_combo_seen2_pearson_top20_de_non_dropout: nan\n",
      "scGPT - INFO - test_unseen_single_pearson_delta: 0.6155381653776693\n",
      "scGPT - INFO - test_unseen_single_pearson_delta_de: 0.7955997135623811\n",
      "scGPT - INFO - test_unseen_single_pearson_delta_top20_de_non_dropout: 0.7941164267404693\n",
      "scGPT - INFO - test_unseen_single_pearson_top20_de_non_dropout: 0.9749507618278279\n"
     ]
    }
   ],
   "source": [
    "test_loader = pert_data.dataloader[\"test_loader\"]\n",
    "test_res = eval_perturb(test_loader, best_model, device)\n",
    "test_metrics, test_pert_res = compute_metrics(test_res)\n",
    "print(test_metrics)\n",
    "\n",
    "# save the dicts in json\n",
    "with open(f\"{save_dir}/test_metrics.json\", \"w\") as f:\n",
    "    json.dump(test_metrics, f)\n",
    "with open(f\"{save_dir}/test_pert_res.json\", \"w\") as f:\n",
    "    json.dump(test_pert_res, f)\n",
    "\n",
    "deeper_res = deeper_analysis(pert_data.adata, test_res)\n",
    "non_dropout_res = non_dropout_analysis(pert_data.adata, test_res)\n",
    "\n",
    "metrics = [\"pearson_delta\", \"pearson_delta_de\"]\n",
    "metrics_non_dropout = [\n",
    "    \"pearson_delta_top20_de_non_dropout\",\n",
    "    \"pearson_top20_de_non_dropout\",\n",
    "]\n",
    "subgroup_analysis = {}\n",
    "for name in pert_data.subgroup[\"test_subgroup\"].keys():\n",
    "    subgroup_analysis[name] = {}\n",
    "    for m in metrics:\n",
    "        subgroup_analysis[name][m] = []\n",
    "\n",
    "    for m in metrics_non_dropout:\n",
    "        subgroup_analysis[name][m] = []\n",
    "\n",
    "for name, pert_list in pert_data.subgroup[\"test_subgroup\"].items():\n",
    "    for pert in pert_list:\n",
    "        for m in metrics:\n",
    "            subgroup_analysis[name][m].append(deeper_res[pert][m])\n",
    "\n",
    "        for m in metrics_non_dropout:\n",
    "            subgroup_analysis[name][m].append(non_dropout_res[pert][m])\n",
    "\n",
    "for name, result in subgroup_analysis.items():\n",
    "    for m in result.keys():\n",
    "        subgroup_analysis[name][m] = np.mean(subgroup_analysis[name][m])\n",
    "        logger.info(\"test_\" + name + \"_\" + m + \": \" + str(subgroup_analysis[name][m]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
